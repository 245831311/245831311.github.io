[{"title":"Spark2.x脑图","url":"/2023/12/27/spark2.x脑图学习/","content":"\n\n![image](/images/bdata/Spark2x脑图.png)\n\n\n\n","tags":["Spark"],"categories":["大数据"]},{"title":"深挖Iceberg","url":"/2023/07/26/深挖iceberg/","content":"\n\n# Iceberg 是什么?\n\nIceberg是一个开源表格式的存储中间层，基于hdfs/Amazon S3等存储引擎之上，spark/flink等计算引擎之下的中间层。\n\nIceberg能够支持秒级延迟的流批一体组件\n\n# Iceberg特性\n\n1.schema演变：支持增，改，删表、重命名、重排序\n\n2.隐藏分区：能够通过函数方式动态指定分区，减少不必要的分区值的生成\n\n3.分区模式演变：支持表分区更改，并不会影响原来sql逻辑\n\n4.版本回溯:可以恢复到任务一个版本的数据\n\n5.无需分布式引擎，单表支持\n\n# Iceberg技术点以及背后的原理\n\n![image](/images/bdata/Iceberg基础图.jpg)\n\n## 基础元素：\n\nMetadata:元数据信息，记录Table结构信息、 分区策略、数据版本以及当前使用的snapshot序列号；命名xxxxx.metadata.json\n\nSnapshot:快照，记录了Table某一时刻的状态，记录了当前manifest list的引用。 命名snap-xxxxx.avro\n\nManifest list:保存了一系列的manifest file 的列表清单，同时伴随着每个分区字段的数值范围信息。\n\nManifest file:记录了一系列的Data files文件信息，而且还记录Data file的分区数据和列级统计信息，包括分区字段最大值、最小值、文件大小、文件\n\n路径、行数等。\n\nData file:实际数据文件，一般格式orc、parquet等\n\n上述每次基于checkpoint commit都会生成。\n\n## V1、V2表：是iceberg table两种不同类型的表\n\nV1表：支持流批读写，只有datafile的概念，数据不能被删除，适用的场景适合日志场景、用户行为数据这种一次性数据的场景（没有删改）\n\nV2表：基于V1表做了扩展，支持upsert的功能，基于Merge On Read理念，支持批读写、流写入，不支持流读。在datafile概念上增加了deletefile的\n\n概念，实现了数据的去重方案。具体通过equality delete 与position delete两种方式。一般在manifest list中记录哪些是data file或者delete file文件\n\n&#x9;equality delete:等值删除\n\n&#x9;position delete:位置删除\n\n由于 datafile与deletefile存在顺序的问题，无法确定数据的一致性，因此引入了sequence number的序列号，以解决数据读取的一致性。\n\n## 快速扫描的原理：目的是快速获取指定文件\n\n两步：\n\n&#x9;Manifest file 过滤：先通过manefest list上的分区字段数值范围定位到manifest file列表\n\n&#x9;Data file 过滤：然后通过manifest file上的分区数据，以及分区字段最大最小值过滤数据文件\n\n# iceberg使用过程中的问题\n\n&#x9;1.坏表：出现在commit的时候，iceberg异常导致了文件丢失，以致于整个Table崩溃.\n\n&#x9;2.基于checkpoint时间批量插入，导致小文件众多\n","tags":["Flink","Iceberg"],"categories":["大数据"]},{"title":"Flink Sql源码分析","url":"/2023/07/10/Flink Sql源码分析/","content":"\n# 1. &#x20;flink-connector-jdbc源码分析\n\n入口：resources/META_INF.services/org.apache.flink.table.factories.Factory\n\n```java\norg.apache.flink.connector.jdbc.table.JdbcDynamicTableFactory\norg.apache.flink.connector.jdbc.catalog.factory.JdbcCatalogFactory\n```\n\n## 1.1. JdbcDynamicTableFactory\n\n管理DynamicTableSink、DynamicTableSource、配置信息Options，DynamicTableSink负责向表写数据，DynamicTableSource负责从表读数据\n\n```java\npublic class JdbcDynamicTableFactory implements DynamicTableSourceFactory, DynamicTableSinkFactory {\n  public DynamicTableSink createDynamicTableSink(Context context);\n  public DynamicTableSource createDynamicTableSource(Context context);\n}\n```\n\n## 1.2. JdbcDynamicTableSource\n\n负责从表读数据。其中ScanRuntimeProvider是扫描表的方式，LookupRuntimeProvider是点查询的方式。\n\n```java\npublic class JdbcDynamicTableSource\n        implements ScanTableSource,\n                LookupTableSource,\n                SupportsProjectionPushDown,\n                SupportsLimitPushDown,\n                SupportsFilterPushDown {\n  public LookupRuntimeProvider getLookupRuntimeProvider(LookupContext context);\n  public ScanRuntimeProvider getScanRuntimeProvider(ScanContext runtimeProviderContext)\n}\n```\n\n## 1.3. JdbcDynamicTableSink\n\n负责向表写数据。\n\n```java\npublic class JdbcDynamicTableSink implements DynamicTableSink {\n  public SinkRuntimeProvider getSinkRuntimeProvider(Context context);\n}\n```\n\n## 1.4. JdbcCatalogFactory\n\n获取database、table等元数据。\n\n# 2. flink sql解析过程\n\n1.  抽象语法树：SQLNode\n\n\n\n1.  逻辑计划：RelNode\n\n\n\n1.  物理计划：RelNode\n\n\n\n1.  Flink算子：Transformation\n\n## 2.1. 抽象语法树：SQLNode\n\n```java\npackage org.apache.flink.table.planner.delegation;\n\npublic class ParserImpl implements Parser {\n  public List<Operation> parse(String statement) {\n    CalciteParser parser = calciteParserSupplier.get();\n    FlinkPlannerImpl planner = validatorSupplier.get();\n\n    // parse the sql query\n    // use parseSqlList here because we need to support statement end with ';' in sql client.\n    SqlNodeList sqlNodeList = parser.parseSqlList(statement);\n    List<SqlNode> parsed = sqlNodeList.getList();\n    return Collections.singletonList(\n            SqlToOperationConverter.convert(planner, catalogManager, parsed.get(0))\n                    .orElseThrow(() -> new TableException(\"Unsupported query: \" + statement)));\n  }\n}\n```\n\n\n\n## 2.2. **逻辑计划：RelNode**\n\n```java\npackage org.apache.calcite.sql2rel;\n\npublic class SqlToRelConverter {\n  public RelRoot convertQuery(SqlNode query, final boolean needsValidation\n\t\t\t\t\t\t, final boolean top) {}\n}\n```\n\n## 2.3. **物理计划：RelNode**\n\n```java\npackage org.apache.calcite.plan.hep;\n\n// 基于规则的优化器\npublic class HepPlanner extends AbstractRelOptPlanner {\n  private void applyRules(Collection<RelOptRule> rules, boolean forceConversions) {}\n}\n```\n\n## 2.4. **Flink算子：Transformation**\n\n```java\npackage org.apache.flink.table.planner.plan.nodes.exec.batch;\n\npublic class BatchExecSink extends CommonExecSink implements BatchExecNode<Object> {\n  protected Transformation<Object> translateToPlanInternal(PlannerBase planner, ExecNodeConfig config) {}\n}\n```\n\n\n\n# 3. flink sql如何关联flink-connector-jdbc包\n\n## 3.1. flink sql task：\n\n```java\nSourceStreamTask.LegacySourceFunctionThread.run():\n  StreamSource.run():\n    InputFormatSourceFunction.run():\n      JdbcRowDataInputFormat.openInputFormat():\n        //创建jdbc连接\n        Connection dbConn = connectionProvider.getOrEstablishConnection();\n```\n\n## 3.2. flink-connector-jdbc包创建JdbcRowDataInputFormat\n\n```java\nJdbcDynamicTableSource.getScanRuntimeProvider():\n  new JdbcRowDataInputFormat()\n```\n\n\n\n\n\n# 4. inner join和lookup join测试\n\n1.  通过tenv.explainSql(sql)输出抽象语法树、逻辑执行计划、物理执行计划\n\n\n\n1.  转成DataStream API，通过env.getExecutionPlan()输出flink算子\n\n\n\n1.  lookup join是一条条地lookup，效率很低\n\n\n\n## 4.1. inner join:\n\n1.  where条件会下推\n\n\n\n1.  limit不会下推\n\n```java\n@Test\npublic void scan() {\n    Configuration conf = new Configuration();\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment(conf);\n    EnvironmentSettings settings = EnvironmentSettings.newInstance().inBatchMode().build();\n    StreamTableEnvironment tenv = StreamTableEnvironment.create(env, settings);\n\n    JdbcCatalog jdbcCatalog = new JdbcCatalog(Thread.currentThread().getContextClassLoader(),\n            \"mysql\", \"gacnio-community\",\n            \"hycan-read\", \"g8AxryVH*r%G3f\",\n            \"jdbc:mysql://192.168.1.192:3317\");\n    tenv.registerCatalog(jdbcCatalog.getName(), jdbcCatalog);\n    tenv.useCatalog(jdbcCatalog.getName());\n\n    String sql = //\n            \"select ua.id, ua.content_id, ua.action_type, ua.create_time, ua.create_id, uc.content \\n\" +\n                    \"from `gacnio-community`.user_action ua \\n\" +\n                    \"join `gacnio-community`.ugc_content uc \\n\" +\n                    \"on ua.content_id = uc.id \\n\" +\n                    \"where ua.type = 1 and ua.content_type = 1 limit 10\";\n    String plan = tenv.explainSql(sql, ExplainDetail.ESTIMATED_COST);\n    System.out.println(plan);\n\n    TableResult result = tenv.executeSql(sql);\n    result.print();\n}\n```\n\n\n\n## 4.2. lookup join：\n\n1.  配置：表options：'lookup.cache'='PARTIAL'，sql：FOR SYSTEM\\_TIME AS OF ua.proctime\n\n\n\n1.  一条条lookup\n\n```java\n@Test\npublic void lookup() {\n    Configuration conf = new Configuration();\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment(conf);\n    EnvironmentSettings settings = EnvironmentSettings.newInstance().inBatchMode().build();\n    StreamTableEnvironment tenv = StreamTableEnvironment.create(env, settings);\n\n    String sql1 = //\n            \"CREATE TABLE user_action(\\n\" +\n            \"\\tid int,\\n\" +\n            \"\\tcontent_id int,\\n\" +\n            \"\\taction_type int,\\n\" +\n            \"\\ttype int,\\n\" +\n            \"\\tcontent_type int,\\n\" +\n            \"\\tcreate_time timestamp,\\n\" +\n            \"\\tcreate_id int,\\n\" +\n            \"\\tproctime AS PROCTIME()\\n\" +\n            \")\\n\" +\n            \"WITH(\\n\" +\n            \"\\t'connector'='jdbc',\\n\" +\n            \"\\t'url'='jdbc:mysql://192.168.1.192:3317/gacnio-community',\\n\" +\n            \"\\t'table-name'='user_action',\\n\" +\n            \"\\t'username'='hycan-read',\\n\" +\n            \"\\t'password'='g8AxryVH*r%G3f'\\n\" +\n            \");\";\n\n    String sql2 = \"CREATE TABLE ugc_content(\\n\" +\n            \"\\tid int,\\n\" +\n            \"\\tcontent string\\n\" +\n            \")\\n\" +\n            \"WITH(\\n\" +\n            \"\\t'connector'='jdbc',\\n\" +\n            \"\\t'url'='jdbc:mysql://192.168.1.192:3317/gacnio-community',\\n\" +\n            \"\\t'table-name'='ugc_content',\\n\" +\n            \"\\t'username'='hycan-read',\\n\" +\n            \"\\t'password'='g8AxryVH*r%G3f',\\n\" +\n            \"\\t'lookup.cache'='PARTIAL',\\n\" +\n            \"\\t'lookup.partial-cache.max-rows'='1000'\\n\" +\n            \");\";\n\n    String sql3 = \"select ua.id, ua.content_id, ua.action_type, ua.create_time, ua.create_id, uc.content\\n\" +\n            \"from user_action as ua\\n\" +\n            \"join ugc_content FOR SYSTEM_TIME AS OF ua.proctime as uc\\n\" +\n            \"on ua.content_id = uc.id\\n\" +\n            \"where ua.type = 1 and ua.content_type = 1 limit 10\";\n\n    String[] sqls = new String[] {sql1, sql2};\n    for (String sql : sqls) {\n        TableResult result = tenv.executeSql(sql);\n        result.print();\n    }\n\n    String plan = tenv.explainSql(sql3, ExplainDetail.ESTIMATED_COST);\n    System.out.println(plan);\n\n    TableResult result = tenv.executeSql(sql3);\n    result.print();\n\n}\n```\n\n","tags":["Flink"],"categories":["大数据"]},{"title":"Flink内存模型","url":"/2023/06/29/Flink内存模型/","content":"\n\n\n# Flink内存模型\n\n## JobManager 内存模型\nJobManager 是 Flink 集群的控制单元,负责调度与协调TaskManager的任务执行\n\n### 内存组成讲解\n![JobManager](/images/bdata/FlinkJobManager任务图.png)\n\n\n![Flink-1.16JobManager内存模型](https://nightlies.apache.org/flink/flink-docs-release-1.16/fig/process_mem_model.svg)\n\n\n| 组成部分 | 配置参数 | 描述 |\n| --- | --- | --- |\n| JVM Heap | \tjobmanager.memory.heap.size | JobManager 的 JVM 堆内存。 |\n| Off-heap Memory | jobmanager.memory.off-heap.size | JobManager 的堆外内存（直接内存或本地内存）。\n |\n| JVM Metaspace | jobmanager.memory.jvm-metaspace.size | Flink JVM 进程的 Metaspace |\n| JVM Overhead | jobmanager.memory.jvm-overhead.min; jobmanager.memory.jvm-overhead.max; jobmanager.memory.jvm-overhead.fraction | 用于其他 JVM 开销的本地内存，例如栈空间、垃圾回收空间等。该内存部分为基于进程总内存的受限的等比内存部分。 |\n\n  \t \n\n## TaskManager 内存模型\nFlink 的 TaskManager 负责执行用户代码\n\n### 内存组成讲解\n\n![taskManager flink ui1.16](/images/bdata/FlinkTaskManager任务图.png)\n\n![TaskManager1.16内存模型](https://nightlies.apache.org/flink/flink-docs-release-1.16/fig/detailed-mem-model.svg)\n\n| 组成部分 | 配置参数 | 描述 |\n| --- | --- | --- |\n| Framework Heap Memory | \ttaskmanager.memory.framework.heap.size | Flink JVM框架内存 |\n| Task Heap Memory | taskmanager.memory.task.heap.size | 用于 Flink 应用的算子及用户代码的 JVM 堆内存。 |\n| Managed memory | taskmanager.memory.managed.size；taskmanager.memory.managed.fraction | 由 Flink 管理的用于排序、哈希表、缓存中间结果及 RocksDB State Backend 的本地内存。 |\n| Framework Off-heap Memory |taskmanager.memory.framework.off-heap.size | 框架堆外内存（Framework Off-heap Memory）\ttaskmanager.memory.framework.off-heap.size\t用于 Flink 框架的堆外内存（直接内存或本地内存） |\n| Task Off-heap Memory | taskmanager.memory.task.off-heap.size | 任务堆外内存（Task Off-heap Memory）\ttaskmanager.memory.task.off-heap.size\t用于 Flink 应用的算子及用户代码的堆外内存（直接内存或本地内存）。 |\n| Network Memory | taskmanager.memory.network.min；taskmanager.memory.network.max；taskmanager.memory.network.fraction | 用于任务之间数据传输的直接内存（例如网络传输缓冲）。该内存部分为基于 Flink 总内存的受限的等比内存部分。这块内存被用于分配网络缓冲 |\n| JVM Metaspace | taskmanager.memory.jvm-metaspace.size | Flink JVM 进程的 Metaspace |\n| JVM Overhead\t | taskmanager.memory.jvm-overhead.min；taskmanager.memory.jvm-overhead.max；taskmanager.memory.jvm-overhead.fraction | 用于其他 JVM 开销的本地内存，例如栈空间、垃圾回收空间等。该内存部分为基于进程总内存的受限的等比内存部分。 |\n\n\n\n## 参考\n1. [Flink1.16 TaskManager内存配置](https://nightlies.apache.org/flink/flink-docs-release-1.16/zh/docs/deployment/memory/mem_setup_tm/)\n1. [Flink1.16 JobManager内存配置](https://nightlies.apache.org/flink/flink-docs-release-1.16/zh/docs/deployment/memory/mem_setup_jobmanager/)","tags":["Flink"],"categories":["大数据"]},{"title":"Iceberg v1与v2表读取分析","url":"/2023/06/01/Iceberg v1与v2读取分析/","content":"\n\n# 1.背景\n\n对于千万级别数据量的情况下，出现了v1,v2表读数据的超时问题，在这篇文章中，具体对比一下相同v1,v2表中读取的表现。\n\n# 2.测试方式\n\n## 2.1 准备\n\nV1建表sql\n\n```\n-- from table hycan-ums.message_push_detail_0\nCREATE TABLE IF NOT EXISTS iceberg.ods_hycan_ums.ods_message_push_detail_v1_notpart (\n    `id` bigint not null,\n    `message_config_id` bigint,\n    `message_content_id` bigint,\n    `task_id` bigint,\n    `push_type` string,\n    `user_id` int,\n    `phone` string,\n    `nickname` string,\n    `message_snapshot` string,\n    `push_status` string,\n    `third_msg_id` string,\n    `view` int,\n    `open_status` string,\n    `create_id` bigint,\n    `create_time` timestamp,\n    `update_id` bigint,\n    `update_time` timestamp,\n    `_create_date` string,\n    primary key(`id`) NOT ENFORCED\n)\nwith (\n    'format' = 'PARQUET',\n    'format-version' = '1',\n    'write.metadata.previous-versions-max' = '10',\n    'write.metadata.delete-after-commit.enabled' = 'true'\n)\n\n```\n\nV2建表sql\n\n```\n-- from table hycan-ums.message_push_detail_0\nCREATE TABLE IF NOT EXISTS iceberg.ods_hycan_ums.ods_message_push_detail_v2_notpart (\n    `id` bigint not null,\n    `message_config_id` bigint,\n    `message_content_id` bigint,\n    `task_id` bigint,\n    `push_type` string,\n    `user_id` int,\n    `phone` string,\n    `nickname` string,\n    `message_snapshot` string,\n    `push_status` string,\n    `third_msg_id` string,\n    `view` int,\n    `open_status` string,\n    `create_id` bigint,\n    `create_time` timestamp,\n    `update_id` bigint,\n    `update_time` timestamp,\n    `_create_date` string,\n    primary key(`id`) NOT ENFORCED\n)\nwith (\n    'format' = 'PARQUET',\n    'format-version' = '2',\n    'write.metadata.previous-versions-max' = '10',\n    'write.metadata.delete-after-commit.enabled' = 'true',\n    'write.upsert.enabled' = 'true'\n)\n\n```\n\n## 2.2 读取结果\n\n### 2.2.1 V1表读取结果\n\n![v1读取结果](/images/bdata/v1读取分析.jpg)\n\n### 2.2.2 V2表读取结果\n\n![v2读取结果](/images/bdata/v2读取分析.jpg)\n\n## 3 思考\n\n### 为什么造成这个问题\n\n1.v1表与v2表功能差异\n\nV1定义了如何来管理大型分析型的表，包括元数据文件、属性、数据类型、表的模式，分区信息，以及如何写入与读取。\nV2表则是在V1表基础上进行了扩展，首要的是实现了行级数据的更新与删除功能，引入了delete file记录需要删除的数据\n\n删除行数据的方式分为两种：Equality Deletes和Position Deletes。\n\n2.如何确认猜想?\n\n可以通过源码进行debug,目前经过排查确认在获取数据的时候进行了delete file过滤，导致问题.\n![delete file慢问题](/images/bdata/Iceberg源码读取分析.jpg)\n\n3.解决方案\n定期合并delete files小文件\norder优化、bloomfilter？\n","tags":["大数据","Iceberg"],"categories":["大数据"]},{"title":"大数据总览（必看）","url":"/2021/09/03/大数据总览/","content":"\n## 总览图\n\n![大数据总览图](/images/bdata/大数据总览.png)\n\n## 说明\n\n上图是在大数据开发组上将近一年多的开发经验累积的知识点，以便日后能快速预览。","tags":["大数据"],"categories":["大数据"]},{"title":"Spark Sql基础知识点","url":"/2021/08/27/spark sql学习/","content":"\n# Spark Sql基础知识点\n\n## Spark Sql 总体图\n\n![spark-sql](/images/bdata/spark-sql.png)\n\n## Spark Sql 功能图\n\n## 基础知识点\n\nDataSet概念：\nDataSet代表被分配的数据集合\n\nDataFrame概念：\nDataFrame是dataSet组织的列名集合。可看作是关系数据库的二维数据表，但相比于此，更具有丰富优化。它可从多个数据源构建，如hive tables、已有RDD、文件等\n\n\n## 思考\n\n为什么要使用Spark Sql？Hive Sql不是能够足够支持？\n\n因为Hive中底层执行sql是需要转化成mapreduce程序来执行，众所周知，mapreduce的程序计算模型效率相对比较慢，而且程序的复杂性会相对比较高。因此，Spark Sql能有效解决这个问题，因为是RDD执行效率会更快。\n\n## demo例子\n\n1.读取json文件demo\n```Java\nSparkConf conf = new SparkConf().setAppName(\"default\").setMaster(\"local\");//.setJars(jars);\n        conf.set(\"spark.executor.memory\", \"512m\");\n        conf.set(\"spark.executor.cores\", \"1\");\n        sc = new JavaSparkContext(conf);\n        \n        //创建spark session\n        SparkSession spark = SparkSession\n        \t\t  .builder()\n        \t\t  .appName(\"Java Spark SQL basic example\")\n        \t\t  .config(\"spark.some.config.option\", \"some-value\")\n        \t\t  .getOrCreate();\n\t\t\n\t\tDataset<Row> df = spark.read().json(\"./src/main/java/org/jay/spark/areaInfo.json\");\n\n\t\tDataset<Row> df2 = df.select(\"address\");\n\t\t\n\t\tdf2.show();\n\t\t\n\t\t\n\t\t//输出schema\n\t\tdf.printSchema();\n\n\t\t//Register the DataFrame as a SQL temporary view\n\t\tdf.createOrReplaceTempView(\"people\");\n\t\tDataset<Row> namesDF = spark.sql(\"SELECT address.city FROM people\");\t\t\n\t\t//数据输出\n\t\tnamesDF.show();\n```\n\n2.创建schema的例子\n```Java\n\nSparkConf conf = new SparkConf().setAppName(\"default\").setMaster(\"local\");//.setJars(jars);\n        conf.set(\"spark.executor.memory\", \"512m\");\n        conf.set(\"spark.executor.cores\", \"1\");\n        sc = new JavaSparkContext(conf);\n        \n        //创建spark session\n        SparkSession spark = SparkSession\n        \t\t  .builder()\n        \t\t  .appName(\"Java Spark SQL basic example\")\n        \t\t  .config(\"spark.some.config.option\", \"some-value\")\n        \t\t  .getOrCreate();\n\t\t\n        \n        JavaRDD<HostBean> rdd = spark.read().text(\"./src/main/java/org/jay/spark/itcast.log\").javaRDD().map(new Function<Row, HostBean>() {\n\n\t\t\t@Override\n\t\t\tpublic HostBean call(Row v1) throws Exception {\n\t\t\t\tString line = v1.toString();\n\t\t\t\tString[] strs = line.split(\"\\t\");\n\t\t\t\tHostBean bean = new HostBean();\n\t\t\t\tbean.setHost(strs[1]);\n\t\t\t\tbean.setTime(strs[0]);\n\t\t\t\treturn bean;\n\t\t\t}\n\t\t});\n\n        //创建schema\n        List<StructField> fields = new ArrayList<>();\n        for (String fieldName : \"time host\".split(\" \")) {\n          StructField field = DataTypes.createStructField(fieldName, DataTypes.StringType, true);\n          fields.add(field);\n        }\n        StructType schema = DataTypes.createStructType(fields);\n        //将rdd转为row\n        JavaRDD<Row> rowRDD = rdd.map((Function<HostBean, Row>) record -> {\n        \t  return RowFactory.create(record.getTime(), record.getHost());\n        \t});\n        //创建df\n        Dataset<Row> df = spark.createDataFrame(rowRDD,schema);\n        \n        //Dataset<Row> df = spark.createDataFrame(rdd, HostBean.class);\n        \n        df.createOrReplaceTempView(\"test\");\n        \n        Dataset<Row> host = spark.sql(\"SELECT name FROM test\");\n\n```\n\n\n# 参考网站\n\n1.[Spark Sql](http://spark.apache.org/sql/)\n\n2.[Spark Sql Guide](http://spark.apache.org/docs/latest/sql-programming-guide.html)\n\n","tags":["大数据"],"categories":["大数据"]},{"title":"Spark Streaming基础知识点","url":"/2021/08/27/spark streaming学习/","content":"\n# Spark Streaming基础知识点\n\n## Spark Streaming 功能图\n\n## Spark Streaming 特性\n\n1. 易用：能够通过API创建应用\n2. 容错：自身能够恢复丢失的操作或者工作的状态\n3. 易整合到spark体系中\n\n## 基础知识点\n\n- DStream概念：DStream是基础抽象,代表了持续性的流式数据。在内部实现上，DStream表示一系列连续的RDD\n\n- DStream相关操作(参照官网)\n\nDStream的Transformations\n名称 | 功能\n---|---\nmap（func） | Return a new DStream by passing each element of the source DStream through a function func.\nflatMap(func) | Similar to map, but each input item can be mapped to 0 or more output items.\nfilter(func) | Return a new DStream by selecting only the records of the source DStream on which func returns true.\nrepartition(numPartitions) | Changes the level of parallelism in this DStream by creating more or fewer partitions.\nunion(otherStream) | Return a new DStream that contains the union of the elements in the source DStream and otherDStream.\ncount() | Return a new DStream of single-element RDDs by counting the number of elements in each RDD of the source DStream.\nreduce(func) | Return a new DStream of single-element RDDs by aggregating the elements in each RDD of the source DStream using a function func (which takes two arguments and returns one). The function should be associative so that it can be computed in parallel.\ncountByValue() | When called on a DStream of elements of type K, return a new DStream of (K, Long) pairs where the value of each key is its frequency in each RDD of the source DStream.\nreduceByKey(func, [numTasks]) | When called on a DStream of (K, V) pairs, return a new DStream of (K, V) pairs where the values for each key are aggregated using the given reduce function. Note: By default, this uses Spark's default number of parallel tasks (2 for local mode, and in cluster mode the number is determined by the config property spark.default.parallelism) to do the grouping. You can pass an optional numTasks argument to set a different number of tasks.\njoin(otherStream, [numTasks]) | When called on two DStreams of (K, V) and (K, W) pairs, return a new DStream of (K, (V, W)) pairs with all pairs of elements for each key.\ncogroup(otherStream, [numTasks]) | When called on a DStream of (K, V) and (K, W) pairs, return a new DStream of (K, Seq[V], Seq[W]) tuples.\ntransform(func) | Return a new DStream by applying a RDD-to-RDD function to every RDD of the source DStream. This can be used to do arbitrary RDD operations on the DStream.\nupdateStateByKey(func) | Return a new \"state\" DStream where the state for each key is updated by applying the given function on the previous state of the key and the new values for the key. This can be used to maintain arbitrary state data for each key.\n\n\n主要讲解常用Operation\n\n1.UpdateStateByKey Operation\n\n能够将前后的数据通过给出的函数整合起来，如统计之类的功能\n\nJava的Demo\n```java\nFunction2<List<Integer>, Optional<Integer>, Optional<Integer>> updateFunction =\n  (values, state) -> {\n    Integer newSum = ...  // add the new values with the previous running count to get the new count\n    return Optional.of(newSum);\n  };\n```\n\n```java\nJavaPairDStream<String, Integer> runningCounts = pairs.updateStateByKey(updateFunction);\n```\n\n2.Window Operations\n\n窗口函数，通过滑动窗口间隔来进行计算\n\n3.Transform Operation\n\nTransform允许DStream上执行任意的RDD-to-RDD函数。通过该函数可以方便的扩展Spark API\n\n4.Output Operations\n\n能够将DStream的数据输出到多个外部系统\n\n\n\n## 参考\n1. [Spark Streaming guide](http://spark.apache.org/docs/latest/streaming-programming-guide.html#a-quick-example)","tags":["Spark"],"categories":["大数据"]},{"title":"Spark入门知识","url":"/2021/08/27/spark入门知识/","content":"\n# Spark入门知识\n\n## Spark总体图\n\n![image](/images/bdata/spark.jpg)\n\n## Spark基础知识\n\n### Spark RDD算子\n\n- RDD算子：分布式数据集,能并行计算操作的且具有高可靠、可容错、自动感知的集合\n\n\n- RDD分为两种：1.Transformation(转换):延迟执行；2.Action(动作)：马上执行\n\n- RDD主要属性：\n\n    1.作用于分区\n    \n    2.多个不同算子RDD\n    \n    3.可以依赖于不同RDD\n    \n    4.默认key-value 分区\n    \n    5.能自动选择数据位置执行RDD操作（计算任务会尽可能分配到数据库的存储位置）\n\n\n- RDD 依赖关系\n\n窄依赖：指的是每一个父RDD只会传递到唯一的子RDD中\n\n宽依赖：指定是每一个父RDD能传递到1个或多个的子RDD中\n\n\n- RDD常用算子介绍\n\nTransformation算子\n名称 | 功能\n---|---\nmap（func） | 返回新rdd,可用于将输入元素经过转换获得类似map形式\nfilter(func) | 返回新rdd,可用于过滤元素\nflatMap（func） | 返回新rdd,先扁平化,后map\nmapPartitions(func) | 作用于分区的map\nmapPartitionsWithIndex(func) | 作用于分区的map，有每个分区的索引值\nreduceByKey(func, [numTasks]) | 经过函数func合并相同的key,返回rdd\ngroupByKey([numTasks]) |    合并相同的key,生成迭代器\nunion(otherDataset) |  两个RDD求并集，返回RDD\nintersection(otherDataset)  |  对源RDD和参数RDD求交集后返回一个新的RDD\ndistinct([numTasks]))  |  对源RDD去重\nsortBy(func,[ascending], [numTasks]) | 经过函数排序RDD\n\n\nAction算子\n\n名称 | 功能\n---|---\nreduce(func) | 通过func函数聚集RDD中的所有元素\ncollect() | 以数组的形式返回数据集的所有元素\ncount() | 返回RDD的元素个数\nfirst() | 返回RDD的第一个元素（类似于take(1)）\ntake(n) | 返回第n个元素\nsaveAsTextFile(path) | 将RDD数据保存至文件系统中\ncountByKey() | 针对(K,V)类型的RDD，返回一个(K,Int)的map，表示每一个key对应的元素个数。\nforeach(func) | 在每个RDD中执行func元素\n\n- RDD 其他信息\n\n广播变量：针对同一个app，共享数据到不同的worker上面\n\nLineage:将创建RDD的一系列信息记录下来，记录RDD的元数据和转换行为，以防RDD部分分区丢失的时候可以重新对这部分分区进行计算\n\nRDD提供缓存功能:cache()\n\nRDD提供checkPoint功能,可以将某阶段RDD数据存储到分布式的系统中（如hdfs）\n\n\n### Spark执行结构\n\n![spark-sql](/images/bdata/spark.png)\n\nDriver:用户提交的应用程序代码在spark中运行起来就是一个driver，用户提交的程序运行起来就是一个driver，他是一个一段特殊的excutor进程，这个进程除了一般excutor都具有的运行环境外，这个进程里面运行着DAGscheduler,Tasksheduler Schedulerbackedn等组件。\n\nMaster:管理所有的worker,进而资源调度\nWorker:管理当前计算节点,worker会启动一个executor来完成真正计算\nExecutor:真正执行任务的jvm\n\n\n\n\n\n\n\n\n\n\n","tags":["Spark"],"categories":["大数据"]},{"title":"kettle在项目中应用","url":"/2021/08/20/kettle在项目中应用/","content":"\n## 背景\n\n随着发展，公司后续对接的项目对大数据量的存储和清洗需求越来越旺盛，我有幸接触这个项目并成为其中开发一员，致力于构建了一个底层的ETL清洗服务。这也是我首次调部门的第一个项目。\n\n## Kettle的介绍\n\nKettle从名称就可以知道“水壶”，顾名思义就是封装了很多内置功能，它是一个ETL的开源工具。Kettle就像一个容纳器，将很多ETL所需要的功能都涵盖进去，形成一个独立的生态系统。\n\n### 功能介绍\n\n下图可以看出,kettle包含了丰富的功能。\n\n![Kettle功能图](/images/bdata/kettle功能图.png)\n\n<html>\n<center>kettle功能图</center>\n</html>\n\n### 为什么使用kettle\n\n基于Kettle开发了一段时间，也逐渐深入了解到kettle的优势。以下是我使用Kettle以来个人的观点：\n\n优势：\n- 内置众多的成熟稳定开源组件，天然支持多种ETL业务场景。\n- kettle设计是基于职责单一原则，各个组件独立，不相互依赖。因此提高重用性。\n- 构建任务脚本简单，通过PC客户端拖拉组件的方式就能轻松实现转化任务。因此不用有编程基础的人都能够自行实现。\n- kettle有独立的官网，上面文档较为完善，但是可能市面上不怎么流行，网上关于kettle的问题并不是很多。\n\n\n劣势：\n- 组件繁多，有额外的学习门槛。\n- 没有提供Web端的开发页面，只有PC客户端，因此开发人员只能通过客户端调试并开发。\n- 由于基于开源组件开发，调试难度相对较大。线上部署测试难度大。\n- 天然包含众多组件，偏重量级开源框架，因此打包会比较大。\n- 不支持对非结构化文本的解释，如非结构化网页html、爬虫、不支持对流的操作和传输、难以支持逻辑较为复杂的业务流程，如数据融合，数据分析等。\n- 开发自定义组件相对复杂，调试比较难。\n\n我大大小小也基于kettle开发过几十个脚本，但是往全公司推广确实举步维艰，因为需要学习成本，这个也跟公司的架构有关系（主要原因）。一旦脚本众多，维护起来就越来越麻烦，特别对于过于复杂的脚本来说，没几多人愿意维护起来。\n\n### Kettle安装与使用\n\n[Kettle安装使用](http://note.youdao.com/noteshare?id=28505b7348b9d73ed38d8da36bfd1425&sub=171D26FDD37442F184CA9B8947192B95)\n\n### 集成Kettle\n\n1. 添加Maven\n```\n<kettle.version>8.3.0.0-371</kettle.version>\n\n<dependency>\n\t<groupId>pentaho-kettle</groupId>\n\t<artifactId>kettle-core</artifactId>\n\t<version>${kettle.version}</version>\n</dependency>\n<dependency>\n\t<groupId>pentaho-kettle</groupId>\n\t<artifactId>kettle-engine</artifactId>\n\t<version>${kettle.version}</version>\n</dependency>\n<dependency>\n\t<groupId>pentaho-kettle</groupId>\n\t<artifactId>kettle-dbdialog</artifactId>\n\t<version>${kettle.version}</version>\n</dependency>\n```\n\n需要额外添加Pentaho自身的仓库，不然下载不了对应的Jar包\n```\n<repositories>\n  \t<repository>\n      <id>pentaho-public</id>\n      <name>Pentaho Public</name>\n      <url>http://nexus.pentaho.org/content/groups/omni</url>\n    </repository>\n</repositories>\n\t\n```\n\n2. 代码集成\n\n- 加载插件并进行kettle环境的初始化\n```\n@Override\npublic boolean init() {\n\ttry {\n\t\tif (pluginDir != null) {\n\t\t\t// Load plugins\n\t\t\tStepPluginType.getInstance().getPluginFolders().add(new PluginFolder(pluginDir, false, true));\n\t\t}\n\t\tKettleEnvironment.init();\n\t} catch (KettleException e) {\n\t\te.printStackTrace();\n\t\tLog.error(\"kettle executor init\",e);\n\t\treturn false;\n\t}\n\treturn true;\n}\n```\n\n- 执行Trans任务具体实现\n```java\n/**\n * \n * @param filePath  脚本路径\n * @param paramMap  脚本参数\n * @param level 脚本输出日志级别\n * @return\n */\npublic boolean runTrans(String filePath, Map<String, String> paramMap,String level) {\n\t\tTrans trans = null;\n\t\ttry {\n\t\t\t\n\t\t\tLOG.info(\"Running trans {}...\", filePath);\n\t\t\tlong st = System.currentTimeMillis();\n\t\t\t\n\t\t\tTransMeta transMeta = new TransMeta(filePath);    //构建Tran文件元数据对象\n\t\t\t\n\t\t\ttrans = new Trans(transMeta);   //构建Trans任务\n\n            //设置Trans里面输入的参数\n\t\t\tif (paramMap != null) {\n\t\t\t\tfor( String param: paramMap.keySet() ) {\n\t\t\t\t\ttrans.setParameterValue( param, paramMap.get(param));\n\t\t\t\t\ttransMeta.setParameterValue( param, paramMap.get(param));\n\t\t\t\t}\t\t\n\t\t\t\ttrans.activateParameters();\n\t\t\t}\n\t\t\t//执行Trans任务的脚本\n\t\t\ttrans.execute(null);\n\t\t\ttrans.waitUntilFinished();\n\t\t\t\n\t\t\tif (trans.getErrors() > 0) {\n\t\t\t\tLOG.error(\"There are errors while running transformation! Error Code: {}\", trans.getErrors());\n\t\t\t\treturn false;\n\t\t\t} else {\n\t\t\t\tlong dt = System.currentTimeMillis() - st;\n\t\t\t\tLOG.info(\"Run trans {} finish in {} ms\", filePath, dt);\n\t\t\t\treturn true;\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t\tif(!trans.isFinished()){\n\t\t\t\ttrans.stopAll();\n\t\t\t}\n\t\t} \n\t\treturn false;\n\t}\n```\n\n3. 运行\n\n到了这部基本上已经可以跑kettle生成的trans的脚本，如果还想增加调度的功能话可以集成quartz调度包、市面上比较流行的saturn、xxl-job等调度框架，或者基于公司的业务架构来自行实现调度框架也是可以。以上的框架我也有使用过并进行对比和集成。后面会有一章节额外说明，这里就不详细说了。\n\n\n\n## 参考\n\n[kettle官网](https://community.hitachivantara.com/s/article/data-integration-kettle)\n","tags":["大数据"],"categories":["大数据"]},{"title":"kettle自定义插件开发","url":"/2021/08/19/Kettle自定义插件开发/","content":"\n## 背景\n\n随着业务种类越来越多，kettle内置的插件也逐渐满足不了各种业务需求，因此需要通过kettle自定义插件的方式来满足业务的需求。\n\n## kettle插件\n\n开发kettle的业务插件也有一段时间，整理了一下大概也有十多个，大概如下：\n\n1. ESDB Output组件：Pipeline ESDB Output组件是一个Kettle的扩展插件，用于将数据输出到ESDB（自研发的地球科学数据库）中。\n\n1. ESDB 字段映射组件：要用于将数据字段名称映射成规范的编码。比如我们提供了一份《气象行业字段标准编码》的文件，里面包含了CIMISS字段、IDEA字段与标准编码的映射。那么在采集CIMISS数据，或者IDEA数据时，就可以通过该组件，将字段名转换为标准的编码，最后才通过ESDB Output插件，进行入库。\n每个行业（如气象、水利等），都可以整理一份字段标准编码CSV文件, 然后利用该组件进行自动匹配。规范字段编码的意义，在于对于不同的系统（比如不同省份的相似系统），数据查询的时候，可以通过统一的字段进行查询。比如地表温度，可以通过gst字段进行查询，无论该数据是来源于CIMISS，还是来源IDEA，还是来源于本地客户提供的数据。\n\n1. Pipeline 通用组件：pipeline 通用组件,为用户开发自定义转换的插件提供统一的界面展示和配置操作。\n\n1. Pipeline 通用组件-经纬度转换组件：pipeline 通用组件 经纬度转换组件,为用户提供经纬度转换坐标系（WGS84、GCJ_02、BD_09之间相互转换）的功能。\n\n1. Pipeline 通用组件-站点插值组件：pipeline 通用组件-插值组件,为用户提供站点插值成格点数据的功能。\n\n1. Pipeline 通用组件-idea（intgetdata2d接口）格点解析组件：格点解析组件,为用户提供解析intgetdata2d接口格点数据的功能\n1. Pipeline 列合并组件：为用户提供针对某个字段，多行数据合并成一行数据的功能，合并后的对象是一个List对象。\n1. Pipeline 多值映射组件：为用户提供值映射的功能。\n1. Pipeline 通用组件-idea-byte转格点：dea（qpe、qpf接口）byte转格点解析组件,为用户提供byte转格点数据的功能。由于qpe与qpf接口返回格点数据经过base64加密，因此该插件会先base64解密然后将byte转换成格点数据\n1. Pipeline 通用组件-格点双线性插值：为用户格点插值的功能（双线性插值）。\n1. Pipeline 通用组件-气象文件读取插件（网格文件）：\n1. Pipeline 通用组件-RestClientNew插件：提供读取rest接口的功能，主要是增加超时设置，kettle自带的restClient插值没有读取超时机制，如果接口卡住，连接会一直保持，所以新增本插件支持读取超时设置功能。\n1. Pipeline 通用组件-多行数据转JSON插件：多行数据转JSON插件,提供把一行或多行数据根据分组字段合并成json字符串。\n1. Pipeline 图片压缩插件：用于将图片进一步压缩的组件。\n1. Pipeline 图片生成gif动图插件：能够将多张图片生成多张含有时间信息的图片，并将生成后的图片聚合成一张gif动态图片。\n\n## 开发自定义插件\n\n本章简单记录我认为开发属于自己步骤插件的要点，要想完整搭建参考[自定义步骤插件开发](https://help.pentaho.com/Documentation/8.3/Developer_center/Create_step_plugins)。\n\n### 四个接口\n\n开发前提条件首先要了解四个接口\n\n\n接口 | 基础类 | 主要职责\n---|---|---\nStepMetaInterface | BaseStepMeta | 1.存储step设置信息</br>2.验证step设置信息</br>3.序列化step设置信息</br>4.提供获取step类的方法\nStepDialogInterface |  org.pentaho.di.ui.trans.step.BaseStepDialog\t| step属性信息配置窗口\nStepInterface | BaseStep | 执行数据行的功能流程\nStepDataInterface | BaseStepData | 存储处理中的数据状态\n\n以下我结合代码尽量\n\n### 实现StepMetaInterface\n\n该接口主要是对步骤元数据信息进行操作。\n\n接口常用方法介绍：\n\n- setDefault()：每次创建新步骤并将该步骤配置分配或设置为合理的默认值时，都会调用此方法。创建新步骤时，PDI客户端（Spoon）将使用此处设置的值。这是确保将步设置初始化为非空值的好地方。在序列化和对话框填充中，空值的处理可能很麻烦，因此大多数PDI步骤实现对于所有步骤设置都坚持非空值。\n- clone()：在PDI客户端中复制步骤时，将调用此方法。它返回步骤元对象的深层副本。如果步骤配置存储在可修改的对象（例如列表或自定义帮助对象）中，则实现类必须创建正确的深层副本，这一点至关重要。\n\n- getXML()：每当步骤将其设置序列化为XML时，PDI都会调用此方法。在PDI客户端中保存转换时会调用它。该方法返回一个XML字符串，其中包含序列化的步骤设置。该字符串包含一系列XML标记，每个设置一个标记。辅助类org.pentaho.di.core.xml.XMLHandler构造XML字符串。\n- loadXML()：每当步骤从XML读取其设置时，PDI都会调用此方法。包含步骤设置的XML节点作为参数传入。再次，帮助程序类 org.pentaho.di.core.xml.XMLHandler从XML节点读取步骤设置。\n- saveRep()：每当步骤将其设置保存到PDI存储库时，PDI都会调用此方法。作为第一个参数传入的存储库对象提供了一组用于序列化步骤设置的方法。调用存储库序列化方法时，该步骤将传入的转换ID和步骤ID用作标识符。\n- readRep()：每当步骤从PDI存储库中读取其配置时，PDI都会调用此方法。使用存储库序列化方法时，参数中给出的步骤ID用作标识符。\n\n获取其他实例\n- public StepDialogInterface getDialog()\n- public StepInterface getStep()\n- public StepDataInterface getStepData()\n\n\nStepMetaInterface必须使用Step Java注释对实现的类进行注释。提供以下注释属性：\n属性|描述\n---|---\nid | 该步骤的全局唯一ID\nimage | 步骤的png图标图像的资源位置\nname | 该步骤的简短标签\ndescription\t| 该步骤的详细说明\ncategoryDescription |\t步骤的类别应显示在PDI步骤树中。例如输入，输出，变换等。\ni18nPackageName |如果i18nPackageName在批注属性中提供了该属性，则将name，description和categoryDe​​scription的值解释为 i18n相对于给定包中包含的消息束的键。</br>可以以扩展形式的i18n:<packagename>键来提供键，以指定与i18nPackageName属性中给定的包不同的包。\n\n### 实现StepDialogInterface\n\n该接口主要用于实现窗口的功能，以及设置属性信息的入口。打开步骤设置时候都会实例化dialog传入到StepMetaInterface接口对象并调用open()方法。\n\n接口常用方法介绍：\n\n- open()：仅在确认或取消对话框后，此方法才返回。\n\n### 实现StepInterface\n\nStepInterface当转换运行时，类实现负责实际的行处理。\n\n![StepInterface](/images/bdata/kettle流程.png)\n\n接口常用方法介绍：\n\n- init()：当转换准备开始执行时，将调用该方法初始化资源。\n\n- processRow()：转换开始执行该方法，读取上一步骤传递下来的行数据，直到没有行就调用setOutputDone()返回false。\n\n- dispose()：转换完成后，PDI将调用该方法取消init()分配的资源。\n\n### 实现StepDataInterface\n\n类实现StepInterface不会在其任何字段中存储处理状态。取而代之的StepDataInterface是，使用一个附加的类实现来存储处理状态，包括状态标志，索引，缓存表，数据库连接，文件句柄等\n\n## 部署步骤插件\n\n1. 创建一个包含您的插件类和资源的JAR文件\n1. 创建一个新文件夹，为其命名，然后将您的JAR文件放在该文件夹中\n1. 将刚创建的插件文件夹放置在特定位置，以供PDI查找。根据您使用PDI的方式，您需要按如下方式将插件文件夹复制到一个或多个位置。\n    - 部署到PDI客户端（Spoon）或Carte：\n    - 将plugin文件夹复制到以下位置： design-tools / data-integration / plugins / steps。\n    - 重新启动PDI客户端。重新启动PDI客户端后，可以使用新的作业条目。\n\n## 参考\n\n[Kettle开发中心](https://help.pentaho.com/Documentation/8.3/Developer_center/Embed_and_extend_PDI_functionality)\n\n[扩展Pentaho数据集成](https://help.pentaho.com/Documentation/8.3/Developer_center/Extend_Pentaho_Data_Integration)\n\n[自定义步骤插件开发](https://help.pentaho.com/Documentation/8.3/Developer_center/Create_step_plugins)","tags":["大数据"],"categories":["大数据"]},{"title":"视频总览（必看）","url":"/2021/07/27/视频总览/","content":"\n## 总览图\n\n![视频总览图](/images/video/视频总览.png)\n\n## 说明\n\n上图是在视频开发组上将近一年多的开发经验累积的知识点，以便日后能快速预览。","tags":["视频"],"categories":["视频"]},{"title":"流媒体基础知识点","url":"/2021/07/26/流媒体基础知识点/","content":"\n# 目的\n\n学习流媒体之前，应该要首先知道流媒体相关基础知识点，这样能够更好地掌握流媒体\n\n## 概念\n流媒体是什么？按照我个人理解就是将音视频数据转化成能够在互联网进行播放的一种流式技术。\n\n## 知识点\n\n### 文件格式\n\n操作系统的扩展名，常用的视频保存格式有：mp4、avi、mpg等\n\n### 封装格式\n\n封装格式（Format），也称多媒体容器（Multimedia Container），是将已编码压缩好的视频轨道、音频轨道和元数据（视频基本信息如标题、字幕等）按照一定的格式规范，打包放到一个文件中，形成特定文件格式的视频文件。\n\n### 编解码\n\n硬编解码：通过硬件实现编解码，减轻CPU计算的负担，如GPU等\n\n软编解码：如 H264、H265、MPEG-4等编解码算法，更消耗CPU\n\n\n### 编码格式\n\n视频编码方式将视频数据进行压缩或者解压。一般来说压缩技术都会有损数据的\n\n视频编码格式：\n1. H.26X系列：\n    -   H261：主要在老的视频会议和视频电话产品中使用。\n    -   H263：主要用在视频会议、视频电话和网络视频上。\n    -   H264：视频压缩技术，比较普及和广发使用，在媒体项目中也是会经常接触，目前市面上多数的流媒体服务都支持H264编码的视频\n    -   H265：高效视频压缩技术，同比H264来说压缩效率提高了50%（同画面质量的情况下），而且还支持4K/8K的视频效果，未来会是趋势。但是目前市面上普遍的播放器支持度并不高，flv协议则不支持H265的格式编码的视频。\n1. MPEG系列\n    - MPEG-1第二部分：主要使用在VCD上，有些在线视频也使用这种格式，该编解码器的质量大致上和原有的VHS录像带相当。\n    - MPEG-2第二部分：等同于H.262，使用在DVD、SVCD和大多数数字视频广播系统和有线分布系统（Cable Distribution Systems）中。\n    - MPEG-4第二部分：可以使用在网络传输、广播和媒体存储上，比起MPEG-2和第一版的H.263，它的压缩性能有所提高。\n    -   MPEG-4第十部分：技术上和ITU-TH.264是相同的标准，二者合作，诞生了H.264/AVC标准，ITU-T将其命名为H.264，而ISO/IEC称它为MPEG-4高级视频编码（Advanced Video Coding，AVC）。\n1. AVS：我国自主知识产权的信源编码标准\n\n音频编码格式：\n1. AAC：ACC是MPEG-4中的音频标准（常见）\n1. AMR\n1. PCM\n1. ogg(ogg vorbis音频)\n1. AC3(DVD 专用音频编码)\n1. DTS(DVD 专用音频编码)\n1. APE(monkey’s 音频)\n1. AU(sun 格式)\n1. WMA\n\n\n音频编码方案之间音质比较（AAC，MP3，WMA等）结果： AAC+ > MP3PRO > AAC> RealAudio > WMA > MP3\n\n### 转码\n\n视频转码（Video Transcoding）是指将已经压缩编码的视频码流转换成另一个视频码流\n\n### 转封装\n\n转封装指的是将视频或音频的封装格式进行转换，如将AVI的视频转换为MP4，其间并不会进行音视频的编码和解码工作，而是直接将视频和音频压缩码流从一种封装格式文件中获取出来然后打包成另一种封装格式的文件。相比转码，转封装有两大特点：\n\n    处理速度极快。音视频编解码过程十分复杂，占据了转码的绝大部分时间。转封装不需要进行编码和解码，节约了大量的处理时间。\n\n    音视频质量无损。没有解码（解压缩）和编码（压缩）过程，所以不会有音视频的压缩损伤。\n转封装后的文件与原始文件的分辨率、码率等几乎一致，故播放时也称其为“原画”。\n\n### 码流与码率\n码率（Bitrate）是指视频文件在单位时间内使用的数据流量，也叫码流或码流率，是视频编码中画面质量控制最重要的部分。量度单位为“比特每秒”（bit/s或bps），常使用Kbps（每秒多少千个比特）或Mbps。一般来说同样分辨率下，视频文件的码率越大，压缩比就越小，画面质量就越高。码率越大，说明单位时间内取样率越大，数据流精度就越高，处理出来的文件就越接近原始文件，图像质量越好，画质越清晰，要求播放设备的解码能力也越高。\n\n    当然，码率越大，文件体积也越大，其计算公式是文件体积=时间X码率/8。例如，网络上常见的一部60分钟的码率为1Mbps的720P的视频文件，其体积就大概为3600秒×1Mb/8=450MB。\n    \n### 分辨率\n\n视频分辨率是指视频成像产品所成图像的大小或尺寸。分辨率决定了视频画面细节的精细程度。通常情况下，视频的分辨率越高，所包含的像素就越多，画面就越清晰。\n\n480P : 640 x 480 个像素点\n\n720P : 1280 x 720 个像素点\n\n1080P : 1920 x 1080 个像素点\n\n    分辨率是决定码率的主要因素，不同的分辨率要采用不同的码率。总体而言，视频的分辨率越高，所要求的码率也越大，但并不总是如此，不同分辨率都有合理的码率选择范围。\n    所谓“合理的范围”指的是，如果低于这个范围，视频画面质量会很差；如果高于这个范围，画面提升有限甚至几乎无提升，且浪费网络流量和存储空间。 \n\n\n### 帧率\n帧率（Frame Rate）是单位时间内视频显示帧数的量度单位，也就是每秒钟刷新的图片的帧数，量度单位为“每秒显示帧数”（Frame Per Second，FPS）或“赫兹”\n\n关于帧率有如下几个基础数据：\n\n- 帧率越高，cpu消耗就高\n- 秀场视频直播，一般帧率20fps\n- 普通视频直播，一般帧率15fps\n\n\n### GOP（关键帧间隔）\n\nGOP（Group of Pictures）是一组以 MPEG 编码的影片或视讯串流内部的连续图像，以 I 帧开头，到下一个 I 帧结束\n\n\n- I 帧(Intra Coded Picture)：又称帧内编码帧，为关键帧，是一种自带全部信息的独立帧，无需参考其他图像便可独立进行解码，可以简单理解为一张静态画面。视频序列中的第一个帧始终都是I 帧，每个 GOP 由I 帧开始。\n- P 帧(Predictive Coded Picture)：又称帧间预测编码帧，需要参考前面的I帧才能进行编码。表示的是当前帧画面与前一帧（前一帧可能是I帧也可能是P帧）的差别。解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面。与I帧相比，P帧通常占用更少的数据位，但不足是，由于P帧对前面的P和I参考帧有着复杂的依赖性，因此对传输错误非常敏感\n- B 帧(Bidirectionally Predictive Coded Pictures)：又称双向预测编码帧，也就是B帧记录的是本帧与前后帧的差别。也就是说要解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。B帧压缩率高，但是对解码性能要求较高。\n\nGOP值表示关键帧的间隔(即两个关键帧之间的帧数)，也就是两个IDR帧之间的距离，一个帧组的最大帧数。一般而言，每一秒视频至少需要使用 1 个关键帧。增加关键帧个数可改善视频质量，但会同时增加带宽和网络负载。GOP值（帧数）除以帧率即为时间间隔，如阿里云视频点播默认的GOP值为250帧，帧率为25fps，则时间间隔为10秒。\n\nGOP值需要控制在合理范围，以平衡视频质量、文件大小（网络带宽）和seek效果（拖动、快进的响应速度）等：\n\n```\n1.加大GOP值有利于减小视频文件大小，但也不宜设置过大，太大则会导致GOP后部帧的画面失真，影响视频质量。\n\n2.GOP值也是影响视频seek响应速度的关键因素，seek时播放器需要定位到离指定位置最近的前一个关键帧，如果GOP太大意味着距离指定位置可能越远（需要解码的预测帧就越多）、seek响应的时间（缓冲时间）也越长。\n\n3.由于P、B帧的复杂度大于I帧，GOP值过大，过多的P、B帧会影响编码效率，使编码效率降低。\n\n4.但如果设置过小的GOP值，则需要提高视频的输出码率，以确保画面质量不会降低，故会增加网络带宽。\n```\n\n### IDR 帧对齐\nIDR帧（Instantaneous Decoding Refresh Picture），即时解码刷新帧，是 I 帧的一种。与普通 I 帧的区别在于，一个 IDR 帧之后的所有帧都不能引用该 IDR 帧之前的帧的内容；相反，对于普通的 I 帧，其后的 P 帧和 B 帧可以引用该普通 I 帧之前的其他 I 帧。在编码和解码中为了方便，将首个I帧和其他I帧区别开，称为IDR，这样就方便控制编码和解码流程\n\n### 图像存储格式yuv\n\nYUV格式，与我们熟知的RGB类似，YUV也是一种颜色编码方法。YUV，分为三个分量，“Y”表示明亮度（Luminance或Luma），也就是灰度值；而“U”和“V” 表示的则是色度（Chrominance或Chroma），作用是描述影像色彩及饱和度，用于指定像素的颜色。\n\nYUV与RGB相比：\nYUV是利用一个亮度（Y）、两个色差(U,V)来代替传统的RGB三原色来压缩图像。传统的RGB三原色使用红绿蓝三原色表示一个像素，每种原色占用一个字节（8bit），因此一个像素用RGB表示则需要8 * 3=24bit。\n\n\n\n## 总结\n\n1.码率与分辨率有关系，分辨率决定码率的主要因素，跟帧率没关，帧率关系着画面流畅度和cpu消耗\n\n2.I帧可以看作一张完整的画面，P帧需要与缓存之前画面生成图像，而B帧则就需要记录前后画面画面生成图像。一般来说网络上的电影都会使用B帧，因为压缩率高，带宽消耗相对比较低。压缩率一般是 I帧（7）< P帧（20） < B帧（50）\n\n3.一般来说，硬编码相比一般性能高，效率高，但移植和实现都比较困难，而软编码则实现简单，但性能相比就低一点。\n\n> PS:\n在项目遇到过一次坑就是关于视频YUV的问题，由于海康和大华的颜色编码不是相同，海康设备使用了YV12格式，而大华使用了YUV420格式，但是程序统一使用了YUV420，因此海康的画面出现了色差问题。\n\n# 参考\n[音视频&流媒体的原理以及基础入门知识\n](https://zhuanlan.zhihu.com/p/232291020)\n\n[基础概念](https://help.aliyun.com/document_detail/99380.html?spm=a2c4g.11186623.6.553.28b0c149c65swI)","tags":["视频"],"categories":["视频"]},{"title":"流媒体协议","url":"/2021/07/25/流媒体协议/","content":"\n# 目的\n总结我在流媒体项目中接触到且使用过的所有协议\n\n# 总体\n\n![image](/images/video/agreement.png)\n\n\n## TCP/UDP\n学习流媒体的协议，首当其冲就是学习TCP与UDP的协议，因为基本的协议都是基于这两种协议来传输\n\n## RTP与RTCP\n\n### 定义\nRTP实时流传输协议，是用于Internet上针对多媒体数据流的一种传输协议。RTP位于传输层，基于UDP之上。RTP为Internet上端到端的实时传输提供时间信息和流同步，但并不保证服务质量，服务质量由RTCP来提供。\n\nRTCP是实时传输控制协议，RTCP收集相关媒体连接的统计信息，例如：传输字节数，传输分组数，丢失分组数，jitter，单向和双向网络延迟等，服务器可以利用这些信息动态的改变传输速率，甚至改变净荷的类型。RTCP消息也被封装为UDP数据报进行传输\n\n一般而言,目的传输地址由一个网络地址和一对端口组成，有两个端口：一个给RTP包，一个 给RTCP包，使得RTP/RTCP数据能够正确发送。RTP数据发向偶数的UDP端口，而对应的控制信号RTCP数据发向相邻的奇数UDP端口（偶数的 UDP端口＋1），这样就构成一个UDP端口对。 RTP的发送过程如下，接收过程则相反。\n\n### 协议介绍\n\n#### RTP协议结构\n\n![RTP协议结构](/images/video/RTCP协议.png)\n\n\nRTP分组头部的各字段含义为：\n\nV：RTP版本号。为“10”。\n\nP：填充指示位。P为“1”时表示分组结尾含有1个或多个填充字节，其中这部分不属于有效载荷。\n\nX：扩展指示位。X为“1”时，则表示固定头部后还有一个扩展头部，这种情况较复杂，很少使用。\n\nCC：CSRC计数。指示固定头部后的CSRC的个数\n\nM：标志。\n\nPT：负载类型。表示RTP分组的负载类型。我们常用的有\n\nPayload Type | Codec\n---|---\n0 | PCM μ -Law\n8 | PCM-A Law\n9 | G..722 audio codec\n4 | G..723 audio codec\n15 | G..728 audio codec\n18 | G..729 audio codec\n34 | G..763 audio codec\n31 | G..761 audio codec\n\n序列号：序号顾名思义就是表示RTP分组的次序。初值为随机数，每发送一个增加1。可供接收方检测分组丢失和恢复分组次序。\n\n时间戳：表示RTP分组第一个字节的取样时刻。其初值为随机数，每个采用周期加1。如果每次传送20ms的数据，由于音频的采样频率为8000Hz，即每20ms有160次采样，则每传送20ms的数据，时戳增加160。\n\nSSRC：同步源标识(Synchronous Source)。表示信号的同步源，其值应随机选择，以保证同一个RTP会话中任意两个同步源的SSRC标识不同。\n\nCSRC：分信源(贡献源)标识(Contributing Source)。识别该数据包中的有效载荷的贡献源。换句话说，CSRC标识由混合器插入，其值就是组成复合信号的各个分信号的SSRC标识，用以标识各个组成分信号的信源。RTP分组的头部最多可以包含15个CSRC标识，其数目由CC字段指明。\n\n\n\n\n#### RTCP协议结构\n\n![RTCP](/images/video/RTP协议.jpg)\n\n```\n版本（V）：同RTP包头域。\n\n填充（P）：同RTP包头域。\n\n接收报告计数器（RC）：5比特，该SR包中的接收报告块的数目，可以为零。\n\n包类型（PT）：8比特，SR包是200。\n\n长度域（Length）：16比特，其中存放的是该SR包以32比特为单位的总长度减一。\n\n同步源（SSRC of sender）：SR包发送者的同步源标识符。与对应RTP包中的SSRC一样。\n\nNTP Timestamp（Network time protocol）SR包发送时的绝对时间值。NTP的作用是同步不同的RTP媒体流。\n\nRTP Timestamp：与NTP时间戳对应，与RTP数据包中的RTP时间戳具有相同的单位和随机初始值。\n\nSender’s packet count：从开始发送包到产生这个SR包这段时间里，发送者发送的RTP数据包的总数. SSRC改变时，这个域清零。\n\nSender`s octet count：从开始发送包到产生这个SR包这段时间里，发送者发送的净荷数据的总字节数（不包括头部和填充）。发送者改变其SSRC时，这个域要清零。\n\n同步源n的SSRC标识符：该报告块中包含的是从该源接收到的包的统计信息。\n\n丢失率（Fraction Lost）：表明从上一个SR或RR包发出以来从同步源n(SSRC_n)来的RTP数据包的丢失率。\n\n累计的包丢失数目：从开始接收到SSRC_n的包到发送SR,从SSRC_n传过来的RTP数据包的丢失总数。\n\n收到的扩展最大序列号：从SSRC_n收到的RTP数据包中最大的序列号，\n\n接收抖动（Interarrival jitter）：RTP数据包接受时间的统计方差估计\n\n上次SR时间戳（Last SR,LSR）：取最近从SSRC_n收到的SR包中的NTP时间戳的中间32比特。如果目前还没收到SR包，则该域清零。\n\n上次SR以来的延时（Delay since last SR,DLSR）：上次从SSRC_n收到SR包到发送本报告的延时。\n```\n\n\n根据所携带的控制信息不同RTCP信息包可分为RR（接收者报告包）、SR（源报告包）、SEDS（源描述包）、BYE（离开申明）和APP（特殊应用包）五类5类：\n\n\n类型 | 缩写表示 | 用途 | 描述\n---|---|---|---\n200 | SR（Sender Report）| 发送端报告 | 发送端报告包，用于发送和接收活动源的统计信息；\n201 | RR（Receiver Report）| 接收端报告 | 接收者报告包，用于接收非活动站的统计信息；\n202 | SDES（Source Description Items）| 源点描述 | 源描述包，用于报告和站点相关的信息，包括CNAME；\n203 | BYE | 结束传输 | 断开RTCP包，是站点离开系统的报告，表示结束；\n204 | APP | 特定应用 | 应用特定函数。\n\n\n## RTSP\n\n![image](/images/video/RTSP协议.png)\n\n### 定义\n实时串流协议（应用层）,TCP/IP协议体系中的一个应用层协议，RTSP位于RTP和RTCP之上，可以基于TCP或者UDP来完成数据传输。RTSP实时性比较，扩展性比较好（UDP,TCP传输数据）。rtsp流主要是控制流媒体的行为动作，提供了诸如暂停，快进等控制，而它本身并不传输流媒体数。\n### 协议介绍\n\n1. RTSP结构\n\n```\nrtsp://admin:a12345678@47.106.89.193:10000/h264/ch33/main/av_stream\n```\n\n结构：\nrtsp://user:pwd@host:port/abs_path/content_name\n\nuser:摄像头设备的登陆用户名\n\npwd:摄像头设备的登陆密码\n\nhost:摄像头有效的域名或是IP地址\n\nport:端口号，对于RTSP协议来说，缺省的端口号为554\n\nabs_path:媒体流资源标识\n\n2. 方法定义\n\n方法 | 方向 | 对象 | 要求 | 含义 \n:---:|---|---|---|---\nDESCRIBE | C->S | P，S | 推荐 | 检查演示或媒体对象的描述，也允许使用接收头指定用户理解的描述格式。DESCRIBE的答复-响应组成媒体RTSP初始阶段\nANNOUNCE | C->S,S->C | P，S | 可选 | 当从用户发往服务器时，ANNOUNCE将请求URL识别的演示或媒体对象描述发送给服务器；反之，ANNOUNCE实时更新连接描述。如新媒体流加入演示，整个演示描述再次发送，而不仅仅是附加组件，使组件能被删除\nGET_PARAMETER | C->S,S->C | P，S | 可选 | GET_PARAMETER请求检查URL指定的演示与媒体的参数值。没有实体体时，GET_PARAMETER也许能用来测试用户与服务器的连通情况\nOPTIONS | C->S,S->C | P，S | 要求 | 可在任意时刻发出OPTIONS请求，如用户打算尝试非标准请求，并不影响服务器状态\nPAUSE | C->S | P，S | 推荐 | PAUSE请求引起流发送临时中断。如请求URL命名一个流，仅回放和记录被停止；如请求URL命名一个演示或流组，演示或组中所有当前活动的流发送都停止。恢复回放或记录后，必须维持同步。在SETUP消息中连接头超时参数所指定时段期间被暂停后，尽管服务器可能关闭连接并释放资源，但服务器资源会被预订\nPLAY | C->S | P，S | 要求 | PLAY告诉服务器以SETUP指定的机制开始发送数据；直到一些SETUP请求被成功响应，客户端才可发布PLAY请求。PLAY请求将正常播放时间设置在所指定范围的起始处，发送流数据直到范围的结束处。PLAY请求可排成队列，服务器将PLAY请求排成队列，顺序执行\nRECORD | C->S | P，S | 可选 | 该方法根据演示描述初始化媒体数据记录范围，时标反映开始和结束时间；如没有给出时间范围，使用演示描述提供的开始和结束时间。如连接已经启动，立即开始记录，服务器数据请求URL或其他URL决定是否存储记录的数据；如服务器没有使用URL请求，响应应为201（创建），并包含描述请求状态和参考新资源的实体与位置头。支持现场演示记录的媒体服务器必须支持时钟范围格式，smpte格式没有意义\nREDIRECT | S->C | P，S | 可选 | 重定向请求通知客户端连接到另一服务器地址。它包含强制头地址，指示客户端发布URL请求；也可能包括参数范围，以指明重定向何时生效。若客户端要继续发送或接收URL媒体，客户端必须对当前连接发送TEARDOWN请求，而对指定主执新连接发送SETUP请求\nSETUP | C->S | S | 要求 | 对URL的SETUP请求指定用于流媒体的传输机制。客户端对正播放的流发布一个SETUP请求，以改变服务器允许的传输参数。如不允许这样做，响应错误为\"455 Method Not Valid In This State”。为了透过防火墙，客户端必须指明传输参数，即使对这些参数没有影响\nSET_PARAMETER | C->S,S->C | P，S | 可选 | 这个方法请求设置演示或URL指定流的参数值。请求仅应包含单个参数，允许客户端决定某个特殊请求为何失败。如请求包含多个参数，所有参数可成功设置，服务器必须只对该请求起作用。服务器必须允许参数可重复设置成同一值，但不让改变参数值。注意：媒体流传输参数必须用SETUP命令设置。将设置传输参数限制为SETUP有利于防火墙。将参数划分成规则排列形式，结果有更多有意义的错误指示\nTEARDOWN | C->S | S | 要求 | TEARDOWN请求停止给定URL流发送，释放相关资源。如URL是此演示URL，任何RTSP连接标识不再有效。除非全部传输参数是连接描述定义的，SETUP请求必须在连接可再次播放前发布\n\n\n\n1. 交互流程\n```\nC表示RTSP客户端,S表示RTSP服务端\n\n1. 第一步：查询服务器端可用方法\n1.C->S:OPTION request //询问S有哪些方法可用\n\n1.S->C:OPTION response //S回应信息的public头字段中包括提供的所有可用方法\n\n2. 第二步：得到媒体描述信息\n2.C->S:DESCRIBE request //要求得到S提供的媒体描述信息\n\n2.S->C:DESCRIBE response //S回应媒体描述信息，一般是sdp信息\n\n3. 第三步：建立RTSP会话\n3.C->S:SETUP request //通过Transport头字段列出可接受的传输选项，请求S建立会话\n\n3.S->C:SETUP response //S建立会话，通过Transport头字段返回选择的具体转输选项，并返回建立的Session ID;\n\n4. 第四步：请求开始传送数据\n4.C->S:PLAY request //C请求S开始发送数据\n\n4.S->C:PLAY response //S回应该请求的信息\n\n5. 第五步： 数据传送播放中\nS->C:发送流媒体数据 // 通过RTP协议传送数据\n\n6. 第六步：关闭会话，退出\n6.C->S:TEARDOWN request //C请求关闭会话\n\n6.S->C:TEARDOWN response //S回应该请求\n```\n\n\n\n4. RTSP与HTTP区别\n- RTSP中客户端和服务器都可以发出请求,HTTP只能客户端发起请求；\n- RTSP相比HTTP提供多种方法定义\n- RTSP传输一般需要2-3个通道，命令和数据通道分离，HTTP和RTMP一般在TCP一个通道上传输命令和数据\n\n\n\n## SDP/SIP\n\n### 定义\nSIP与SDP这两个协议会在国标视频上会出现比较多。其中一般会与RTSP等协议共同\n\nSIP它是一个基于文本的应用层控制协议，独立于底层传输协议，用于建立、修改和终止IP网络上的双方或多方多媒体会话\n\nSDP（Session Description Protocol）是一个用来描述多媒体会话的应用层控制协议，它是一个基于文本的协议，用于会话建立过程中的媒体类型和编码方案的协商等\n\n### 协议介绍\n\n#### SIP介绍\n\n1. SIP 角色\n\n角色 | 作用\n---|---\n用户代理（UA） | 用户代理客户端（UAC）和用户代理服务器（UAS）组成，UAC负责发起呼叫，UAS负责接收呼叫并作出响应\n代理服务器（PS） | 通过它把来自用户代理客户端（UAC）的请求转发到用户代理服务端（UAS），并把UAS的响应消息转发回UAC\n注册服务器（register server） | 是具有接收注册请求、将请求中携带的信息进行保存并提供本域内位置服务的功能服务器\n重定向服务器（redirect server） | 负责规划SIP呼叫路由。它将获得的呼叫下一跳地址信息告诉呼叫方，以使呼叫方根据此地址直接向下一跳发出请求，此后重定向服务器退出呼叫过程。\n\n2. SIP请求\n```\n是客户端发给服务器激活一个SIP操作的消息，由一个方法名（Method）、一个请求URI（Request-URI）和一个协议版本 （SIP-Version）组成，三个部分之间以空格（SP）间隔。\n\nRequest-Line  =  Method + SP + Request-URI + SP + SIP-Version + CRLF\n\nRFC中定义了6中请求：\n\nINVITE：表明接收用户或服务被邀请加入一个会话；也可以使用这种方式来修改先前建立会话的特性；成功响应（200 OK）表明被叫方愿意参与会话；\n\nACK：确认UAC已经接收到了INVITE请求的最终响应（只与INVITE请求一起使用）；用于结束一个200 OK响应；若INVITE请求中不含有会话描述信息，ACK可以包含一个最终会话描述的消息体；\n\nOPTION：UA用此向UAS查询它的功能；\n\nBYE：用于终结一个先前建立的会话；\n\nCANCEL：使UAC和网络服务器取消一个正在进行的请求（如INVITE）；\n\nREGISTER：客户端注册其目前的位置信息；\n```\n\n\n3. SIP响应\n```\n服务器向客户端发送SIP响应，指明客户端先前发送给服务器的SIP请求的状态；由一个协议版本（SIP-Version），一个状态码（Status-Code）和一个原因说明（Reason-Phrase）组成，类似于请求消息，三个部分之间也以空格字符（SP）间隔。\n\nStatus-Line := SIP-Version + SP + Status-Code + SP + Reason-Phrase + CRLF\n\n状态码是一个100～699之间的3位正整数（具体参见后面附录），它表示对于一个请求消息的响应结果；原因说明是一串可以显示的字符，用于对响应的状态码进行简短说明。\n\n1xx：临时响应 （Provisional）；之前的请求消息已经收到，并准备接着处理后面的请求消息。\n\n2xx：成功响应 （Success）； 操作成功，请求消息已被收到并且成功地处理。\n\n3xx：重定向响应 （Redirection）； 服务器向客户端返回其它可能的位置，客户端应当根据响应中包含的地址信息向另一个服务器重发请求消息。\n\n4xx： 客户端错误 （Client Error）； 请求由于客户端的错误而失败，客户端可以根据响应状态码修改并重发刚才的请求消息。\n\n5xx：服务器错误 （Server Error） ；请求由于服务器的错误而失败，客户端可以向另一个服务器重发请求消息。\n\n6xx：全局错误（Global Failure）； 请求失败，客户端不应该再向任何服务器重发该请求消息。\n```\n\n4. 标题头\n```\n遵从HTTP标题头（RFC2616）定义的同样格式：每个标题头由字段名，紧跟着冒号(:)和字段组成。\n\n主要标题头（详情参见\n\nSIP常见头域（header）说明\n\nFrom：定义请求发起者（通常是发送者AOR），包含SIP或SIP URI和一个可选的显示名字；\n\nTo：定义了请求的接收者（通常是接收者AOR），包含SIP或SIP URI和一个可选的显示名字；因重定向和转移，SIP请求不一定发送给‘希望的’接收者；\n\nCall-ID：定义了一系列的SIP消息，对所有由对话中的UA发送的所有SIP请求和响应，Call-ID必须唯一；\n\nCseq：由一个整数值和一个方式名称组成，在一个对话中标识和序列SIP请求，也区分重传和新消息；\n\nVia：定义请求路径和响应要发送的地址；\n\nContact：定义US希望接收新SIP请求的SIP或SIPS URI（实际地址）；\n\nAllow：列出产生SIP消息的UA所支持的功能集合；\n\nSupported：列出所有UA支持的SIP扩展（RFC3262）；\n\nRequire：包含远端UA必须支持的SIP扩展；\n\nContent-Type：请求或响应的消息体类型；\n\nContent-Length：请求或响应的消息体的大小（十进制）；\n```\n\n#### SDP协议\n\nSDP协议内容(具体可参考国标规范文档)\n```\n1 v=:Version ，表示协议的版本号\n2 o=: Origin,表示源。值域中各项的含义依次是username(用户名)，sess-id(会话ID)，sess-version(会话版本号)，nettype(网络类型)，addrtype(地址类型)，unucast-address(单播地址)。\n3 s=:Session Name,表示本sdp所描述的session的名称\n4 c=:Connection Data 链接数据。其中值域中以空格分配的两个字段分贝是网络类型和网络地址，以后的RTP流就会发到该地址上。\n5 b=:Badwidth type，带宽类型\n6 t=:Timing ,起止时间，0表示无限\n7 m=:audio Media Type,媒体类型。audio表示音频，50452表示音频端口号，RTP/AVR是传输协议；后面是支持的Codec类型，与RTP流中的PayloadType(载荷类型)相对应，在这里分别是8,0,98和101,8和0分别代表PCMA和PCMU，他们属于静态编码，大于95的编码都属于动态编码，需要在后面使用“a=rtpmap”进行说明。\n8 a=: Attributes,属性。 它用于描述上面的音频的属性。如本例中98代表8000hz的ILBC编码，101代表RFC2833dtmf事件。a=sendrecv表示该媒体流可用于收和发，其他的还有sendonly(仅收)，recvonly(仅发)和inactive(不收不发)\n9 v=:Video，视频。\n```\n\n#### 点播流程\n\n为了更加熟悉SIP的流程，截取点播流程的流程图。可以看出，SIP传输过程当中都会有SDP的使用。\n\n![SIP点播流程](/images/video/wps2.png)\n\n\n## RTMP/HTTP-HLS/HTTP-FLV\n\nRTMP、HTTP-HLS与HTTP-FLV目前市面上比较常用的流媒体协议，都能基于浏览器来观看。\n\n- RTMP：实时消息传送协议，基于FLASH播放器的私有协议，默认使用端口 1935。RTMP一般被切割一个个块（chunk）的形式基于TCP协议上传输的明文协议。市面上的摄像头基本都会支持RTMP的形式，而且RTMP一般延时在 1-3s 之间相对延时较低，不过目前来说谷歌禁用了FLASH，可能对RTMP支持可能有所减弱\n\n- HTTP-HLS：HTTP Live Streaming，苹果公司基于HTTP的流媒体传输协议。工作原理是在服务端将视频流切片成ts小文件形式，通过m3u8索引文件访问ts文件。不过HLS的延迟在10s以上，且文件比较碎片化比较难以保存，但是有利有弊，正因为有ts文件落地，可支持回放等功能。\n- HTTP-FLV：Flash Video，主要是将音视频数据封装成FLV格式，然后通过 HTTP 协议传输给客户端。像B站都是使用该协议进行PC页面播放。FLV延迟比较低。\n\n- ws-flv：ws-flv直播技术基本与http-flv一致，无非是传输介质换成了websocket协议，除了解除了http-flv不能同时打开过多同域名下的直播窗口的限制，其他技术特性、参数基本与http-flv一致。目前看，ws-flv既适合视频监控(可以同时打开多路监控视频)也适合视频直播行业，是rtmp很高的升级替代方案。\n- webrtc：webrtc是谷歌主导的视频通话技术标准，目前各大主流浏览器都兼容该标准。通过该技术，用户可以在浏览器上实现无插件的视频通话，该技术也可以用于实现低延时的视频直播。目前业界也有很多基于webrtc的应用和产品，但是很多局限于视频聊天等低延时交互式场景，在视频监控领域，目前还尚未流行。而且该技术栈目前还在持续更新，技术难点太多，要与视频监控领域融合还需时日。\n\n### 协议介绍\n\n#### RTMP\n\n![RTMP](/images/video/hls-message.png)\n\n\n具体可参考：[RTMP协议详解](https://www.jianshu.com/p/d511d59b185c)\n\n\n#### HLS\n\n[HLS协议详解](https://www.jianshu.com/p/d511d59b185c)\n\n以下简单介绍下m3u8的相关内容\n\n![m3u8](/images/video/hls.png)\n\n```\nEXTM3U：每个M3U文件第一行必须是这个tag，请标示作用\n\nEXT-X-MEDIA-SEQUENCE:7\n每一个media URI 在 PlayList中只有唯一的序号，相邻之间序号+1, 一个media URI并不是必须要包含的，如果没有，默认为0\n\nEXTINF:\nduration 指定每个媒体段(ts)的持续时间（秒），仅对其后面的URI有效，title是下载资源的url\n\nEXT-X-TARGETDURATION\n指定最大的媒体段时间长（秒）。所以#EXTINF中指定的时间长度必须小于或是等于这个最大值。这个tag在整个PlayList文件中只能出现一 次（在嵌套的情况下，一般有真正ts url的m3u8才会出现该tag）\n\nEXT-X-KEY\n表示怎么对media segments进行解码。其作用范围是下次该tag出现前的所有media URI，属性为NONE 或者 AES-128。NONE表示 URI以及IV（Initialization Vector）属性必须不存在， AES-128(Advanced EncryptionStandard)表示URI必须存在，IV可以不存在。\n对于AES-128的情况，keytag和URI属性共同表示了一个key文件，通过URI可以获得这个key，如果没有IV（Initialization Vector）,则使用序列号作为IV进行编解码，将序列号的高位赋到16个字节的buffer中，左边补0；如果有IV，则将改值当成16个字节的16进制数。\n\nEXT-X-PROGRAM-DATE-TIME\n将一个绝对时间或是日期和一个媒体段中的第一个sample相关联，只对下一个meida URI有效，格式如#EXT-X-PROGRAM-DATE-TIME:\nFor example: #EXT-X-PROGRAM-DATE-TIME:2010-02-19T14:54:23.031+08:00\n\nEXT-X-ALLOW-CACHE\n是否允许做cache，这个可以在PlayList文件中任意地方出现，并且最多出现一次，作用效果是所有的媒体段。格式如下：#EXT-X-ALLOW-CACHE:\n\nEXT-X-PLAYLIST-TYPE\n提供关于PlayList的可变性的信息， 这个对整个PlayList文件有效，是可选的，格式如下：#EXT-X-PLAYLIST-TYPE:：如果是VOD，则服务器不能改变PlayList 文件；如果是EVENT，则服务器不能改变或是删除PlayList文件中的任何部分，但是可以向该文件中增加新的一行内容。\n\nEXT-X-ENDLIST\n表示PlayList的末尾了，它可以在PlayList中任意位置出现，但是只能出现一个，格式如下：#EXT-X-ENDLIST\n\nEXT-X-MEDIA\n被用来在PlayList中表示相同内容的不用语种/译文的版本，比如可以通过使用3个这种tag表示3中不用语音的音频，或者用2个这个tag表示不同角度的video在PlayLists中。这个标签是独立存在的，属性包含：\nURI：如果没有，则表示这个tag描述的可选择版本在主PlayList的EXT-X-STREAM-INF中存在;\nTYPE:AUDIO and VIDEO;\nGROUP-ID:具有相同ID的MEDIAtag，组成一组样式；\nLANGUAGE：确定使用的主要语言\nNAME：人类可读的语言的翻译\nDEFAULT：YES或是NO，默认是No，如果是YES，则客户端会以这种选项来播放，除非用户自己进行选择。\nAUTOSELECT：YES或是NO，默认是No，如果是YES，则客户端会根据当前播放环境来进行选择（用户没有根据自己偏好进行选择的前提下）。\n\nEXT-X-STREAM-INF\n指定一个包含多媒体信息的 media URI 作为PlayList，一般做M3U8的嵌套使用，它只对紧跟后面的URI有效，格式如下：#EXT-X-STREAM-INF:有以下属性：\nBANDWIDTH：带宽，必须有。\nPROGRAM-ID：该值是一个十进制整数，惟一地标识一个在PlayList文件范围内的特定的描述。一个PlayList 文件中可能包含多个有相同ID的此tag。\nCODECS：不是必须的。\nRESOLUTION：分辨率。\nAUDIO：这个值必须和AUDIO类别的“EXT-X-MEDIA”标签中“GROUP-ID”属性值相匹配。\nVIDEO：同上\n```\n\n\n#### FLV\n\n[FLV协议详解](https://zhuanlan.zhihu.com/p/287220)\n\n\n### 性能对比\n\n![协议性能对比](/images/video/协议性能对比.png)\n\n\n## PES/TS/ES流\n\nPES、TS、ES流都是用于封装视频、音频数据的数据流。\n\nES流（Elementary Stream）：基本码流，不分段的音频、视频或其他信息的连续码流。\n\nPES流：把基本流ES分割成段，并加上相应头文件打包成形的打包基本码流。\n\nPS流（Program Stream）：节目流，将具有共同时间基准的一个或多个PES组合（复合）而成的单一数据流（用于播放或编辑系统，如m2p）。\n\nTS流（Transport Stream）：传输流，将具有共同时间基准或独立时间基准的一个或多个PES组合（复合）而成的单一数据流（用于数据传输）。\n\n## 总结\n上面列了很多我在项目中所有用到过的协议，每种协议都有不同的封装格式以及各自不同属性，个人觉得对于开发者或者使用者来说不一定每种协议都要面面俱到，平常大概知道他们具体作用性能和普遍的属性之类就可以，到真正使用的时候再去深入了解，反而会更高效。以下，我总结下这段时间来对这几个协议的了解：\n    ![协议](/images/video/zlm.png)\n\n\n根据上图可以看出，一般来说推流的方式可能会议国标方式或者接入海康、大华等厂商的摄像头来直接推流到流媒体，而从流媒体转码成flv,hls等不同协议供客户端来拉流访问。\n\n参考\n\n1. [关于RTSP/RTP/RTCP](https://zhuanlan.zhihu.com/p/72917813)\n\n1. [会话初始协议SIP与SDP简介](https://cloud.tencent.com/developer/news/387488)\n\n1. [RTMP、HTTP-FLV、HLS，你了解常见的三大直播协议吗\n](https://zhuanlan.zhihu.com/p/48100533)","tags":["视频"],"categories":["视频"]},{"title":"FFmpeg学习与使用","url":"/2021/07/25/FFmpeg学习与使用/","content":"\n\n## 目的\n\n本节主要记录下FFmpeg的使用方法以及如何用于视频项目上作一个简单的介绍\n\n## 简介\nFFmpeg是一款多媒体处理工具，内部包含了解码、编码、转码、解密的操作命令。正式由于FFmpeg太强大，目前大部分流媒体服务都会或多或小使用到FFmpeg的功能，所以我们有必要学习下FFmpeg的使用指令。\n\n## 常用命令以及解析\n\n### 主要成分：\n\n1. libavformat：用于各种音视频封装格式的生成和解析，包括获取解码所需信息以生成解码上下文结构和读取音视频帧等功能；\n1. libavcodec：用于各种类型声音/图像编解码；\n1. libavutil：包含一些公共的工具函数；\n1. libswscale：用于视频场景比例缩放、色彩映射转换；\n1. libpostproc：用于后期效果处理；\n1. ffmpeg：该项目提供的一个工具，可用于格式转换、解码或电视卡即时编码等；\n1. ffsever：一个 HTTP 多媒体即时广播串流服务器；\n1. ffplay：是一个简单的播放器，使用ffmpeg 库解析和解码，通过SDL显示；\n\n\n### ffprobe\n例子\n```\nffprobe -rtsp_transport tcp -i \"rtsp://10.128.184.34:554/01?Short=1&Token=vEKOlIYbbCFseXHTjO3kbtEKZGZ4eyRExIkPU+yWWPA=&DomainCode=6a7c1a077a004406a344a1f260d86e41&UserId=6&\"\n```\n\n-rtsp_transport tcp/udp：选择以TCP还是UDP方式打开 \n·-i filename：指定输入文件名，rtsp、rtmp、摄像头地址等。\n-show_format filename：展示格式\n-show_frames filename：显示帧信息\n\n### ffplay\n\n播放文件\n```\nffplay xxx.mp3 -ast 1 -loop 10\n```\n-loop num：循环次数\n\n-[ast|vst] 1：选择播放[音频|视频]\n\n### FFmpeg\n\nFFmpeg参数太多，以下是我举例了项目中实际用到的命令。\n\n```\nffmpeg -re -loglevel quiet {[decoder]}  {[tcp]} -i \"{[rtsp]}\"\n```\n·-re：代表按照帧率发送，尤其在作为推流工具的时候一定要加入该参数，否则ffmpeg会按照最高速率向流媒体服务器不停地发送数据\n\n-loglevel [debug|quiet|error]：日志级别记录\n\n·-i filename：指定输入文件名，rtsp、rtmp、摄像头地址等。\n\n截图\n```\nffmpeg  -re -loglevel quiet {[tcp]} -i \\\"{[rtsp]}\\\" -an {[size]}  -vframes 1 -y -f image2 {[pattern]}.jpg\n```\n-an：视频静音\n\n·-y：覆盖已有文件。\n\n·-f fmt：指定格式（音频或者视频格式）。\n\n\n推流转码成h264\n```\nffmpeg -re -loglevel debug  -rtsp_transport tcp -i \"rtsp://10.128.184.34:554/01?Short=1&Token=yWSkzfBj71Yja67n9Y65SXDN97TCCOzBveNwOB53Lh8=&DomainCode=6a7c1a077a004406a344a1f260d86e41&UserId=6&\" -an -s 1280x720  -vcodec smart_h264 -f flv rtmp://192.168.193.168:1935/hls/7a92e703d492aac22614ba670c85018f?secret=035c73f7-bb6b-4889-a715-d9eb2d1925ccSimp\n```\n\n-analyzeduration：设置码流分析时间\n\n-probesize：探测时长，这个设置的时间越长，视频打开得越慢\n\n·-vcodec [codec|smart_h264]：强制使用codec编解码方式（'copy'代表不进行重新编码）,smart_h264实现h264编码\n\n·-s size：指定分辨率（320×240）。\n\n\n```\n{[ffmpeg]} -loglevel error {[decoder]} -i {[rtsp]} {[copy]} {[encoder]} -an -threads 10 -tune zerolatency -crf {[crf]} -g 1 -r {[frameRate]} -preset ultrafast -vcodec smart_h264 -f flv rtmp://192.168.193.168:1935/hls/7a92e703d492aac22614ba670c85018f?secret=035c73f7-bb6b-4889-a715-d9eb2d1925ccSimp\n```\n\n\ncrf num：\n为恒定质量（无比特率目标）和受限质量（最大比特率目标）模式设置质量/大小折衷。有效范围是0到63，数字越大表示质量越低，输出大小越小。仅在设置时使用；默认情况下，仅使用比特率目标\n\nthreads num：选定的编解码器实现支持多线程，则设置要使用的线程数。\n\ntune [zerolatency|fastdecode|psnr|ssim]：主要配合视频类型和视觉优化的参数。zerolatency零延迟，用在需要非常低的延迟的情况下，比如电视电话会议的编码；fastdecode可以快速解码的参数； psnr为提高psnr做了优化的参数；ssim为提高ssim做了优化的参数； \n\npreset type：预设类型。\n\nr num：帧率\n\ng size：设置GOP的大小\n\n\n## 项目中如何是使用\n\n由于ffmpeg太强大，在视频网关的项目中，我们经常会使用到ffmpeg。主要使用到有两方面，一个是截图，一个是将h265的视频数据格式转码成h264或者更改视频的分辨率功能等。为什么在项目中会使用到FFmpeg呢，其实像海康和大华第三方的厂商都会有对应的sdk,但是像截图之类的功能不能很好支持各种分辨率的截图，所以喔们考虑到使用FFmpeg来结合起来，以下是关于项目的流程图。\n\n![FFmpeg使用流程](/images/video/流程图.jpg)\n\n其实在项目上，我们一般会使用FFmpeg来进行截图，如上述说因为能够定制化配置截图得大小以及色差得调节等，而第三方厂商sdk一般都是默认尺寸，扩展性不高（如海康和大华）。而且，使用FFmpeg得扩展性会比较高。但是FFmpeg并不是万能，对于有一些私有的RTSP等可能也会存在失败的情况，所以在项目中如果FFmpeg截图不成功都会采用对应厂商sdk进行兜底截图，保证图片能够生成并且可用。\n\n## 参考\n\n1. [FFmpeg官网](http://www.ffmpeg.org/documentation.html)","tags":["视频"],"categories":["视频"]},{"title":"frp穿透","url":"/2021/07/25/frp穿透/","content":"\n# frp穿透\n\n主要介绍如何将内网摄像头的rtsp通过frp穿透工具映射到互联网上。\n\n准备：\n\n摄像头ip：172.16.10.2\n\n内网服务器：10.144.21.90（与摄像头是互通）\n\n互联网服务器：47.106.89.193\n\nfrp工具包：frp_0.35.1_linux_386.tar.gz\n\n\n## 操作步骤\n\n1. 两台分别安装frp穿透工具\n```\nwget https://github.com/fatedier/frp/releases/download/v0.35.1/frp_0.35.1_linux_386.tar.gz\n```\n\n2. 配置服务端\n\n互联网服务器47.106.89.193作为服务端,配置frps.ini\n\n```\n[common]\nbind_port = 7000    #绑定端口\n\n[rtsp]\nlisten_port = 10000 #监听端口\n```\n\n开启服务端监听命令\n```\nnohup ./frps -c ./frps.ini &\n```\n\n3. 配置客户端\n\n内网服务器10.144.21.90作为客户端,配置frpc.ini\n\n```\n[common]\nserver_addr = 47.106.89.193 #服务端ip\nserver_port = 7000  #服务端绑定的端口\n\n#[ssh]\n#type = tcp\n#local_ip = 127.0.0.1\n#local_port = 22\n#remote_port = 6000\n\n[rtsp]\ntype = tcp\nlocal_ip = 172.16.10.2  #摄像头Ip\nlocal_port = 554    #摄像头端口\nremote_port = 10000 #服务端监听得端口\n```\n\n开启服务端监听命令\n```\nnohup ./frpc -c ./frpc.ini &\n```\n\n4. 结果\n\nrtsp://admin:a12345678@47.106.89.193:10000/h264/ch33/main/av_stream\n\n\n## 参考\n[frp映射摄像头地址及端口](https://www.cnblogs.com/liusingbon/p/12623774.html)\n\n[frp 内网穿透工具](https://www.oschina.net/p/frp?hmsr=aladdin1e1)","tags":["视频"],"categories":["视频"]},{"title":"Gateway源码分析（一）","url":"/2021/07/25/gateway源码分析(一)/","content":"\n## 背景\n\n当选用了SpringCloud Gateway作为视频项目的网关之后,出于学习的心态，看下视频网关是如何构造起来的。\n\n\n## Spring WebFlux学习\n\n阅读源码之前首先学习下WebFlux基础概念和相关常用的API\n\nSpring WebFlux简单说是与Spring MVC类似的一门响应式异步非阻塞Web端控制框架。与Spring MVC有着相同功能的注解\n\n1. 什么是响应式编程(Reactive)\n\n官方解释：\n>The term, “reactive,”  refers to programming models that are built around reacting to change\n响应式编程是一种围绕对变化作出反应而构建的编程模型。\n\n后面给出了例子：\n>network components reacting to I/O events, UI controllers reacting to mouse events, and others. In that sense, non-blocking is reactive, because, instead of being blocked, we are now in the mode of reacting to notifications as operations complete or data becomes available.\n网络组件对IO事件的响应，UI控制器对鼠标事件的响应。从这个意义上说，非阻塞也是响应式,因为我们现在也是在操作完成或者数据可用的时候作出响应的模式，而不是被阻塞。\n\n2. 什么是背压（back pressure）\n\n官方解析：\n>Reactive Streams is a small spec (also adopted in Java 9) that defines the interaction between asynchronous components with back pressure. For example a data repository (acting as Publisher) can produce data that an HTTP server (acting as Subscriber) can then write to the response. The main purpose of Reactive Streams is to let the subscriber control how quickly or how slowly the publisher produces data.\n响应式流是一个小小的规范，定义了带有背压异步组件交互。例如，数据仓库（作为发布者）产生数据使HTTP服务（作为订阅者）能响应。主要目的就是响应式能让订阅者控制发布者发布数据的快与慢。\n\n其实上述说白了就是订阅者能够通过生产者需要多小数据，这样能够以免生产者无限量产生数据压垮订阅者。\n\n3. SpringMVC与WebFlux选择\n![webFlux&SpringMVC](https://docs.spring.io/spring-framework/docs/current/reference/html/images/spring-mvc-and-webflux-venn.png)\n\n- 如果您有运行正常的Spring MVC应用程序，则无需更改。命令式编程是编写，理解和调试代码的最简单方法。您有最大的库选择空间，因为从历史上看，大多数库都是阻塞的。\n\n- 如果您已经在选择无阻塞的Web堆栈，Spring WebFlux可以提供与该领域其他服务器相同的执行模型优势，还可以选择服务器（Netty，Tomcat，Jetty，Undertow和Servlet 3.1+容器），选择编程模型（带注释的控制器和功能性Web端点），以及选择反应式库（Reactor，RxJava或其他）。\n\n- 如果您对与Java 8 lambda或Kotlin一起使用的轻量级功能性Web框架感兴趣，则可以使用Spring WebFlux功能性Web端点。对于要求较低复杂性的较小应用程序或微服务（可以受益于更高的透明度和控制）而言，这也是一个不错的选择。\n\n- 在微服务架构中，您可以混合使用带有Spring MVC或Spring WebFlux控制器或带有Spring WebFlux功能端点的应用程序。在两个框架中都支持相同的基于注释的编程模型，这使得重用知识变得更加容易，同时还为正确的工作选择了正确的工具。\n\n- 评估应用程序的一种简单方法是检查其依赖关系。如果您要使用阻塞性持久性API（JPA，JDBC）或网络API，则Spring MVC至少是通用体系结构的最佳选择。使用Reactor和RxJava在单独的线程上执行阻塞调用在技术上是可行的，但您不会充分利用非阻塞Web堆栈。\n\n- 如果您的Spring MVC应用程序具有对远程服务的调用，请尝试使用active WebClient。您可以直接从Spring MVC控制器方法返回反应类型（Reactor，RxJava或其他）。每个呼叫的等待时间或呼叫之间的相互依赖性越大，好处就越明显。Spring MVC控制器也可以调用其他反应式组件。\n\n\n\n4. WebFlux提供了两种模型\n- 注解控制器（Annotated Controllers）：与Spring MVC有一致的注解，都是基于spring-web模型。一个显著的区别是，WebFlux也支持响应式@RequestBody参数。\n- 函数终端（Functional Endpoints）：基于Lambda,轻量级和函数编程模型。提供了大量的方法来路由和处理请求。与注解控制器（Annotated Controllers）最大区别就是函数端模型能够负责请求的从头到尾的处理而不是只是通过声明注解然后回调。\n\n\n### API\n\n两个Publisher接口：Flux与Mono。两者区别在于Flux是代表多个元素的发布者，Mono是单个元素的发布者.\n\nMono 实现了 Publisher 接口，\n```\nempty()：创建一个不包含任何元素，只发布结束消息的序列。\njust()：可以指定序列中包含的全部元素。创建出来的 Mono序列在发布这些元素之后会自动结束。\njustOrEmpty()：从一个 Optional 对象或可能为 null 的对象中创建 Mono。只有 Optional 对象中包含值或对象不为 null 时，Mono 序列才产生对应的元素。\nerror(Throwable error)：创建一个只包含错误消息的序列。\nnever()：创建一个不包含任何消息通知的序列。\nfromCallable()、fromCompletionStage()、fromFuture()、fromRunnable()和 fromSupplier()：分别从 Callable、CompletionStage、CompletableFuture、Runnable 和 Supplier 中创建 Mono。\ndelay(Duration duration)和 delayMillis(long duration)：创建一个 Mono 序列，在指定的延迟时间之后，产生数字 0 作为唯一值。\ncreate()：通过 create()方法来使用 MonoSink 来创建 Mono。\n```\n\nFlux\n```\njust：可以指定序列中包含的全部元素。创建出来的 Flux 序列在发布这些元素之后会自动结束。\nfromArray、fromIterable、fromStream：可以从一个数组、Iterable 对象或 Stream 对象中创建 Flux 对象。\nempty()：创建一个不包含任何元素，只发布结束消息的序列,在响应式编程中，流的传递是基于元素的，empty表示没有任何元素，所以不会进行后续传递，需要用switchIfEmpty等处理\nerror(Throwable error)：创建一个只包含错误消息的序列。\nnever()：创建一个不包含任何消息通知的序列。使用示例：\nrange(int start, int count)：创建包含从 start 起始的 count 个数量的 Integer 对象的序列。\nintervalMillis(long period)： interval()方法的作用相同，只不过该方法通过毫秒数来指定时间间隔和延迟时间。\ncreate()：与 generate()方法的不同之处在于所使用的是 FluxSink 对象。FluxSink 支持同步和异步的消息产生，并且可以在一次调用中产生多个元素。\n```\n\n## 总结\n\n这一章主要是简单记录下WebFlux的介绍以及简单说明下WebFlux相关的几个概念。WebFlux的官方文档还是相对比较完善的，里面都有挺详细的说明，我就不一一照搬到这里。下一章就开始阅读Gateway的代码，看下Gateway里面是如何使用WebFlux构建网关。\n\n\n\n## 参考\n\n- [webFlux官网](https://docs.spring.io/spring-framework/docs/current/reference/html/web-reactive.html#spring-webflux)\n\n\n- [外行人都能看得懂的WebFlux](https://zhuanlan.zhihu.com/p/92460075)\n\n\n- [最近学到的Lambda表达式基础知识](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&mid=2247485692&idx=1&sn=a6b3f040b13fa2324992b11a927e34dc&chksm=ebd749fddca0c0eb1b05c08ede7ee4a44699584fbc0c3449ec2cac7642fd13819470ec7f44d8&token=1024331018&lang=zh_CN#rd)\n\n\n","tags":["视频"],"categories":["视频"]},{"title":"Gateway源码分析（二）","url":"/2021/07/25/Gateway源码分析(二)/","content":"\n# 背景\n\n这一章开始记录我开始Gateway阅读之路，看下究竟是如何实现网关。\n\n# 个人疑问\n\n1. Gateway的网关框架是如何接收请求并转发\n\n2. 如何执行Filter\n\n3. 如何加载路由、过滤器、断言等信息\n\n\n\n# 源码分析\n\n## 版本\n\n```\n<dependency>\n\t<groupId>org.springframework.cloud</groupId>\n\t<artifactId>spring-cloud-starter-gateway</artifactI>\n\t<version>2.1.0.RELEASE</version>\n</dependency>\n```\n\n## 架构图\n\n还是一样的图\n![Gateway框架](/images/video/gateway网关图.png)\n\n## 组成\n\ngateway-core.jar是gateway的核心包，主要的实现都在里面。阅读代码前最好先知道个个包的主要功能.\n\n![包组成](/images/video/gateway的jar包架构图.png)\n\n- actuate\n\n该包主要是gateway自带的一个控制器GatewayControllerEndpoint，该endpiont提供了关于filter及routes的信息查询以及指定route信息更新的rest api，这给web界面提供管理配置功能提供了极大的便利\n\n- config\n\n该包主要是Gateway的配置实体类，譬如yml上面的配置GatewayProperties、全局的跨域配置GlobalCorsProperties等等。\n\n- discovery\n\n该包主要是实现服务发现的功能。从服务注册中心获取服务注册信息，然后配置相应的路由\n\n- event\n\n该包是一些发布事件的定义。\n\n- filter\n\n该包包含了gateway所有内置的过滤器。\n\n- handler\n\n该包主要包括了所有内置的Predicates断言，RoutePredicateHandlerMapping类是一个实现了将接收请求到转发到filter里面的功能，FilteringWebHandler主要是构造过滤器链。\n\n- route\n\n该包主要是定义路由信息，构造路由等。\n\n- support\n\n该包主要是一些工具方法。用于全局。\n\n\n\n## 源码分析\n\n### 问题一：如何转发请求\n\n#### DispatchHandler类\n\nWebFlux请求转发核心类：DispatchHandler\n\nDispatchHandler内部主要的私有字段：\n\n```java\n@Nullable\nprivate List<HandlerMapping> handlerMappings;\n\n@Nullable\nprivate List<HandlerAdapter> handlerAdapters;\n\n@Nullable\nprivate List<HandlerResultHandler> resultHandlers;\n```\n\n类型 | 解释\n---|---\nHandlerMapping | 映射请求到一个处理器。该映射是基于一定的标准、细节因不同HandlerMapping而不同。</br>例如有注解控制器, 简单URL匹配映射等等。</br>主要的HandlerMapping实现：</br>1.有RequestMappingHandlerMapping对于注解的@RequestMapping。</br>2.RouterFunctionMapping 对应于函数式端点路由。</br>3.SimpleUrlHandlerMappingURI路径模式的显式注册。</br>4.WebHandler的实例\nHandlerAdapter | 帮助DispatcherHandler调用映射的请求的处理器，而不管该处理程序实际上是如何调用的。</br>例如执行一个注解控制器需要解释注解。其主要目的是帮助DispatcherHandler隐藏实现的细节。\nHandlerResultHandler | 处理程序调用的结果并最后确定响应。</br>1.ResponseEntityResultHandler：ResponseEntity，处理@Controller实例。</br>2.ServerResponseResultHandler：ServerResponse，处理函数式端点。</br>3.ResponseBodyResultHandler：处理从@ResponseBody方法和@RestController类的返回值。</br>4.ViewResolutionResultHandler：处理成CharSequence,View, Model, Map, Rendering等其他的模型属性。\n\n\n```java\n@Override\npublic Mono<Void> handle(ServerWebExchange exchange) {\n\tif (this.handlerMappings == null) {\n\t\treturn Mono.error(HANDLER_NOT_FOUND_EXCEPTION);\n\t}\n\treturn Flux.fromIterable(this.handlerMappings)\n\t\t\t.concatMap(mapping -> mapping.getHandler(exchange))\n\t\t\t.next()\n\t\t\t.switchIfEmpty(Mono.error(HANDLER_NOT_FOUND_EXCEPTION))\n\t\t\t.flatMap(handler -> invokeHandler(exchange, handler))\n\t\t\t.flatMap(result -> handleResult(exchange, result));\n}\n```\n\n核心方法主要做了三个步骤：\n\n1. 匹配每一个不同HandlerMapping，使用首先匹配的那个。\n2. 执行器被找到就会找到对应的HandlerAdapter,然后就会将返回结果返回到HandlerResult里。\n3. HandlerResult会给出一个合适的处理器去完成直接写到响应里面或者使用View来渲染的处理。\n\n#### RoutePredicateHandlerMapping类\n\n刚说完DispatchHandler的类，就到HandlerMapping了，类RoutePredicateHandlerMapping实现了HandlerMapping。\n\n其核心私有字段分别有：\n```java\nprivate final FilteringWebHandler webHandler;\n\nprivate final RouteLocator routeLocator;\n\nprivate final Integer managmentPort;\n```\n\nBean类型 | 解释\n---|---\nwebHandler | 构建过滤器的责任链\nrouteLocator | 路由的定义信息\nmanagmentPort | gateway管理端口\n\n\n其核心方法：\n\n```java\n@Override\nprotected Mono<?> getHandlerInternal(ServerWebExchange exchange) {\n\t// don't handle requests on the management port if set\n\tif (managmentPort != null && exchange.getRequest().getURI().getPort() == managmentPort.intValue()) {\n\t\treturn Mono.empty();\n\t}\n\texchange.getAttributes().put(GATEWAY_HANDLER_MAPPER_ATTR, getSimpleName());\n\n\treturn lookupRoute(exchange)\n\t\t\t// .log(\"route-predicate-handler-mapping\", Level.FINER) //name this\n\t\t\t.flatMap((Function<Route, Mono<?>>) r -> {\n\t\t\t\texchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR);\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"Mapping [\" + getExchangeDesc(exchange) + \"] to \" + r);\n\t\t\t\t}\n\n\t\t\t\texchange.getAttributes().put(GATEWAY_ROUTE_ATTR, r);\n\t\t\t\treturn Mono.just(webHandler);\n\t\t\t}).switchIfEmpty(Mono.empty().then(Mono.fromRunnable(() -> {\n\t\t\t\texchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR);\n\t\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\t\tlogger.trace(\"No RouteDefinition found for [\" + getExchangeDesc(exchange) + \"]\");\n\t\t\t\t}\n\t\t\t})));\n}\n```\n\n该核心方法做了几件事：\n\n1. 找到合适的路由lookupRoute方法。\n2. 将路由信息放到ServerWebExchange请求线程的属性里，以便整个运行随时可用。\n3. 执行webHandler中的过滤器链。==（后面会介绍如何执行）==\n\n\nlookupRoute执行过程：\n1. 通过routeLocator的获取所有配置好的路由信息。 ==（后面会介绍如何加载路由信息、过滤器、断言）==\n2. 匹配每一个路由的断言，是否符合，若符合则返回对应的路由信息。若不符合则next()下一个路由的断言匹配。\n\n```java\nprotected Mono<Route> lookupRoute(ServerWebExchange exchange) {\n\treturn this.routeLocator\n\t\t\t.getRoutes()\n\t\t\t//individually filter routes so that filterWhen error delaying is not a problem\n\t\t\t.concatMap(route -> Mono\n\t\t\t\t\t.just(route)\n\t\t\t\t\t.filterWhen(r -> {\n\t\t\t\t\t\t// add the current route we are testing\n\t\t\t\t\t\texchange.getAttributes().put(GATEWAY_PREDICATE_ROUTE_ATTR, r.getId());\n\t\t\t\t\t\treturn r.getPredicate().apply(exchange);\n\t\t\t\t\t})\n\t\t\t\t\t//instead of immediately stopping main flux due to error, log and swallow it\n\t\t\t\t\t.doOnError(e -> logger.error(\"Error applying predicate for route: \"+route.getId(), e))\n\t\t\t\t\t.onErrorResume(e -> Mono.empty())\n\t\t\t)\n\t\t\t// .defaultIfEmpty() put a static Route not found\n\t\t\t// or .switchIfEmpty()\n\t\t\t// .switchIfEmpty(Mono.<Route>empty().log(\"noroute\"))\n\t\t\t.next()\n\t\t\t//TODO: error handling\n\t\t\t.map(route -> {\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"Route matched: \" + route.getId());\n\t\t\t\t}\n\t\t\t\tvalidateRoute(route, exchange);\n\t\t\t\treturn route;\n\t\t\t});\n}\n```\n\n### 问题二：如何执行Filter\n\n\n#### 如何执行Filter(FilteringWebHandler类)\n\n\n执行流程：\n\n1. 初始化时候构造好全局的过滤器集合。\n2. 合并路由上配置的过滤器与全局过滤器\n3. 排序好所有过滤器传入DefaultGatewayFilterChain的责任链里执行。\n\n```\n@Override\npublic Mono<Void> handle(ServerWebExchange exchange) {\n\tRoute route = exchange.getRequiredAttribute(GATEWAY_ROUTE_ATTR);\n\tList<GatewayFilter> gatewayFilters = route.getFilters();\n\n\tList<GatewayFilter> combined = new ArrayList<>(this.globalFilters);\n\tcombined.addAll(gatewayFilters);\n\t//TODO: needed or cached?\n\tAnnotationAwareOrderComparator.sort(combined);\n\n\tif (logger.isDebugEnabled()) {\n\t\tlogger.debug(\"Sorted gatewayFilterFactories: \"+ combined);\n\t}\n\n\treturn new DefaultGatewayFilterChain(combined).filter(exchange);\n}\n```\n\n责任链是一个常用的编程设计模式，它能够将请求与处理步骤解耦，请求操作对链内部的执行透明，而且每个链子都有自己具体实现，能够自由组装复用，不相互影响，使得代码更加简洁。不过责任联在调试方面相对来说比较麻烦，不便于观察等缺点。\n\n看下如何构造一个责任联，内部类DefaultGatewayFilterChain\n的filter方法\n```java\nprivate static class DefaultGatewayFilterChain implements GatewayFilterChain {\n\n\t\tprivate final int index;\n\t\tprivate final List<GatewayFilter> filters;\n\n\t\tpublic DefaultGatewayFilterChain(List<GatewayFilter> filters) {\n\t\t\tthis.filters = filters;\n\t\t\tthis.index = 0;\n\t\t}\n\n\t\tprivate DefaultGatewayFilterChain(DefaultGatewayFilterChain parent, int index) {\n\t\t\tthis.filters = parent.getFilters();\n\t\t\tthis.index = index;\n\t\t}\n\n\t\tpublic List<GatewayFilter> getFilters() {\n\t\t\treturn filters;\n\t\t}\n\n\t\t@Override\n\t\tpublic Mono<Void> filter(ServerWebExchange exchange) {\n\t\t\treturn Mono.defer(() -> {\n\t\t\t\tif (this.index < filters.size()) {\n\t\t\t\t\tGatewayFilter filter = filters.get(this.index);\n\t\t\t\t\tDefaultGatewayFilterChain chain = new DefaultGatewayFilterChain(this, this.index + 1);\n\t\t\t\t\treturn filter.filter(exchange, chain);\n\t\t\t\t} else {\n\t\t\t\t\treturn Mono.empty(); // complete\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t}\n```\n\n\n### 问题三：如何加载路由、过滤器、断言等信息\n\n\n#### RouteDefinitionRouteLocator类\n\n- 获取路由信息\n\n```\n@Override\npublic Flux<Route> getRoutes() {\n\treturn this.routeDefinitionLocator.getRouteDefinitions()\n\t\t\t.map(this::convertToRoute)\n\t\t\t//TODO: error handling\n\t\t\t.map(route -> {\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"RouteDefinition matched: \" + route.getId());\n\t\t\t\t}\n\t\t\t\treturn route;\n\t\t\t});\n\n\n\t/* TODO: trace logging\n\t\tif (logger.isTraceEnabled()) {\n\t\t\tlogger.trace(\"RouteDefinition did not match: \" + routeDefinition.getId());\n\t\t}*/\n}\n```\n\n==this.routeDefinitionLocator.getRouteDefinitions()== 初始化首次加载获取配置文件中定义的路由信息并存于缓存中以便下次使用\n```\npublic CachingRouteDefinitionLocator(RouteDefinitionLocator delegate) {\n\t\tthis.delegate = delegate;\n\t\trouteDefinitions = CacheFlux.lookup(cache, \"routeDefs\", RouteDefinition.class)\n\t\t\t\t.onCacheMissResume(this.delegate::getRouteDefinitions);\n}\n```\n\n==convertToRoute==则是将配置信息定义的路由信息转变为真正内部使用的路由实体，具体实现如下：\n\n1. 组装断言链表\n2. 获取配置信息定义过滤器\n3. 组装成真正路由对象Route\n```\nprivate Route convertToRoute(RouteDefinition routeDefinition) {\n\t\tAsyncPredicate<ServerWebExchange> predicate = combinePredicates(routeDefinition);\n\t\tList<GatewayFilter> gatewayFilters = getFilters(routeDefinition);\n\n\t\treturn Route.async(routeDefinition)\n\t\t\t\t.asyncPredicate(predicate)\n\t\t\t\t.replaceFilters(gatewayFilters)\n\t\t\t\t.build();\n\t}\n```\n\n其实这段代码使用了一个设计模式就是建造者模式。该模式能将构建和实现分离开来，建造者能逐步细化而不影响其它模块功能。不过建造者对产品会依赖，当产品发生变化，建造者相应也需要改变。所以这种模式建议用在比较简化的建造者依赖类上。\n\n```\nreturn Route.async(routeDefinition)\n\t\t\t\t.asyncPredicate(predicate)\n\t\t\t\t.replaceFilters(gatewayFilters)\n\t\t\t\t.build();\n```\n![建造者模式](/images/video/Router的结构图.png)\n\n\n\n“断言”的功能在我看来实现得是非常巧妙的，所有断言正如过滤器一样都有一个共同的父类AbstractRoutePredicateFactory，实现apply的方法。看个例子：\n\nPathRoutePredicateFactory断言类：作用是匹配请求uri资源。可以看出返回的是一个Predicate的实例，这样的好处就是在下次执行只会执行return返回的这一部分代码功能，不再需要执行配置行的代码。\n\n```\n@Override\npublic Predicate<ServerWebExchange> apply(Config config) {\n\tfinal ArrayList<PathPattern> pathPatterns = new ArrayList<>();\n\tsynchronized (this.pathPatternParser) {\n\t\tpathPatternParser.setMatchOptionalTrailingSeparator(config.isMatchOptionalTrailingSeparator());\n\t\tconfig.getPatterns().forEach(pattern -> {\n\t\t\tPathPattern pathPattern = this.pathPatternParser.parse(pattern);\n\t\t\tpathPatterns.add(pathPattern);\n\t\t});\n\t}\n\treturn exchange -> {\n\t\tPathContainer path = parsePath(exchange.getRequest().getURI().getPath());\n\n\t\tOptional<PathPattern> optionalPathPattern = pathPatterns.stream()\n\t\t\t\t.filter(pattern -> pattern.matches(path))\n\t\t\t\t.findFirst();\n\n\t\tif (optionalPathPattern.isPresent()) {\n\t\t\tPathPattern pathPattern = optionalPathPattern.get();\n\t\t\ttraceMatch(\"Pattern\", pathPattern.getPatternString(), path, true);\n\t\t\tPathMatchInfo pathMatchInfo = pathPattern.matchAndExtract(path);\n\t\t\tputUriTemplateVariables(exchange, pathMatchInfo.getUriVariables());\n\t\t\treturn true;\n\t\t} else {\n\t\t\ttraceMatch(\"Pattern\", config.getPatterns(), path, false);\n\t\t\treturn false;\n\t\t}\n\t};\n}\n```\n\n然后通过Flux.zip方法连成一条断言链子\n```\nprivate AsyncPredicate<ServerWebExchange> combinePredicates(RouteDefinition routeDefinition) {\n\tList<PredicateDefinition> predicates = routeDefinition.getPredicates();\n\tAsyncPredicate<ServerWebExchange> predicate = lookup(routeDefinition, predicates.get(0));\n\n\tfor (PredicateDefinition andPredicate : predicates.subList(1, predicates.size())) {\n\t\tAsyncPredicate<ServerWebExchange> found = lookup(routeDefinition, andPredicate);\n\t\tpredicate = predicate.and(found);\n\t}\n\n\treturn predicate;\n}\n\n---------------------------------------------------\n\ndefault AsyncPredicate<T> and(AsyncPredicate<? super T> other) {\n\tObjects.requireNonNull(other, \"other must not be null\");\n\n\treturn t -> Flux.zip(apply(t), other.apply(t))\n\t\t\t.map(tuple -> tuple.getT1() && tuple.getT2());\n}\n```\n\n# 总结\n其实到这里这一章就差不多了，基本上Gateway的主要总体框架功能就这些。这一次的阅读源码能够使我对lambda表达式的用处更深刻，而且，对这种响应式流的理解更进一步了，后续还会持续学习关于netty reactor的用法。","tags":["视频"],"categories":["视频"]},{"title":"nginx支持流媒体","url":"/2021/07/25/nginx支持流媒体/","content":"\n## 简介\n本章介绍如何搭建一个nginx的流媒体服务器，可以直接通过nginx访问hls的m3u8与rtmp的链接。\n\n## 安装\n\n安装nginx其实没有什么值得说，主要是要下载nginx的nginx-rtmp-module模块,编译时候加下此模块就OK了\n\n下载nginx-rtmp-module：https://github.com/arut/nginx-rtmp-module\n\n```\n./configure --prefix=/usr/local/nginx --with-pcre=/home/user/pcre/pcre-8.32 --with-zlib=/home/user/zlib/zlib-1.2.8 --with-openssl=/home/user/openssl/openssl-1.0.1i  --add-module=/home/user/nginx-rtmp-module\n```\n\n## 配置\n\n- RTMP\n```\nrtmp {                #RTMP服务\n   server {\n       listen 1935;  #//服务端口\n       chunk_size 4096;   #//数据传输块的大小\n       application vod {\n         play /opt/video/vod; #//视频文件存放位置。\n       }\n   }\n}\n\n\nhttp {\n    include      mime.types;\n    default_type  application/octet-stream;\n    sendfile        on;\n    keepalive_timeout  65;\n    server {\n        listen      80;\n        server_name  localhost;\n        \n        #配置nginx的rtmp一览页面\n        location /stat {\n                rtmp_stat all;\n            rtmp_stat_stylesheet stat.xsl;\n        }\n        location /stat.xsl {\n           root /etc/rtmpServer/nginx-rtmp-module/;\n        }\n\n        location / {\n            root  html;\n            index  index.html index.htm;\n        }\n\n        error_page  500 502 503 504  /50x.html;\n        location = /50x.html {\n            root  html;\n        }\n    }\n}\n```\n\n\n- HLS\n\n该配置是播放hls的配置\n```\nlocation /hls {  \n    types{  \n        application/vnd.apple.mpegurl m3u8;  \n        video/mp2t ts;  \n    }  \n    suffix m3u8;\n   #配置一个根路径 \n   root /data/baiyun/; \n   add_header Cache-Control no-cache;\n   add_header 'Access-Control-Allow-Origin' '*';\n   add_header 'Access-Control-Allow-Credentials' 'true';\n}\n```\n\n该配置是支持远程推流到nginx负责切片成m3u8的配置\n```\nrtmp {\n    server {\n        listen 1935;\n        chunk_size 4000;\n        #HLS\n        application hls {\n            live on;\n            hls on;\n            #视频流存放地址\n            hls_path /usr/local/nginx/html/hls; \n            hls_fragment 5s;\n        }\n    }\n}\n```\n\n## 参考\n[视频直播点播nginx-rtmp开发手册中文版](https://blog.csdn.net/weiyuefei/article/details/74001589)","tags":["视频"],"categories":["视频"]},{"title":"wireshark抓包并使用","url":"/2021/07/24/wireshark抓包并使用/","content":"\n## 简介\n本篇是记录我在平常抓包过程中如何使用wireshark\n\n## 前提\n\n- wireshark工具\n\n\n## 详解\n\n### 抓包\n\n使用wireshark，首先就要学会怎么抓包，很简单，在linux下使用以下命令\n>tcpdump -i eth0 host [ip] -n -vv -A -w 抓包.pcap\n\n\n### 使用\n\n将抓到的包用wireshark打开就能见到下面的界面\n\n![wireshark界面](/images/video/抓包界面图.png)\n<html>\n<center>图一</center>\n</html>\n           \n                \n这是一份在对接RTSP视频协议时候抓回来的包，很明显可以看到是基于TCP来传输的。以下记录一下我常用到的主要功能：\n\n1. 面板使用\n\n![wireshark面板](/images/video/抓包上方图.png)\n<html>\n<center>图二</center>\n</html>\n\n一般来说，通过面板就能看出交互的具体内容。如图二可以前三行列表可以看出TCP三次握手的交互流程。参考TCP三次握手流程\n\n![image](/images/video/tcp三次握手图.png)\n    \n2. 数据详细区\n\n![wireshark下半部](/images/video/抓包下方图.png)\n<html>\n<center>图三</center>\n</html>\n\n\n整个传输过程的传输信息，具体每一层有什么具体信息可以看下相应的资料。由上往下\n1. 物理层\n2. 数据链路层\n3. 网络层（常用）\n4. 传输层（常用）\n5. 应用层（常用）\n\n\n3. 追踪流\n\n展示更具体交互信息\n\n>右键点击面板信息>追踪流>TCP流\n\n![追踪流](/images/video/抓包协议追踪图.png)\n<html>\n<center>图四</center>\n</html>\n\n4. 统计丢包率\n\n一般来说，我们也会去观察究竟数据的丢包率是多小，对于音视频的数据我们一般观察RTP包，特别是以UDP传输的时候。\n>电话>>RTP>>RTP流\n\n![RTP丢包率](/images/video/抓包rtp统计包.png)\n\n\n\n## 参考\n\n[Wireshark抓包使用指南](https://zhuanlan.zhihu.com/p/82498482)\n","tags":["视频"],"categories":["视频"]},{"title":"选型视频网关","url":"/2021/07/23/选型视频网关/","content":"\n## 背景\n\n随着发展，视频网关也逐步完善，但后期也出现了越来越多的需求，譬如流控、鉴权、业务分发等功能。这些功能原本是直接放在视频网关上面，但是考虑到以后的易于维护、可扩展性、复用、避免代码臃肿、职责单一的问题，就将这部分功能单独抽到一个api网关上面。这样一来我们接下来首要的问题就是选型了。\n\n## 技术对比\n\n![网关选型对比](/images/video/网关选型图.png)\n\n网关说到底最重要的技术选性格是并发能力，以下是Gateway官网作者做了一个压测\n\n![image](/images/video/网关压测性能对比.png)\n\n\n这篇文章是我看了那么多对比做得比较清晰简单的一篇：[压测对比](https://www.edjdhbb.com/2018/12/16/%E7%BD%91%E5%85%B3%E9%80%89%E6%8B%A9%E5%9B%B0%E9%9A%BE%E7%97%87/)\n\n### 为什么选择SpringCloud Gateway\n\n选择Gateway，基于以下几点考虑：\n\n1. 维护成本\n\n虽然Kong的并发能力更高，但是Kong比较适合业务相对简单的网关，且公司大多都是JAVA技术人员，对于JAVA技术栈的系统来说维护起来比较困难。举个例子当业务复杂起来时，维护lua的脚本就会越来越多，因此引入一种新的技术栈成本是一个相对较高的事情。\n\n2. 接入快\n\n相比zuul1.x与Gateway，都是可以无缝对接到spring boot或spring cloud,但相比起来Gateway能支持websocket且并发的能力相对高于zuul，而zuul2.x在后续没有整合到spring上。重要一点是，接入到Gateway相对比较快，开发对应的Filter就能满足业务。\n\n3. 内置功能完善\n\nGateway自带了多种Filter和Router，对于开发一个简单的网关来说是完全足够。像限流之类功能也是需要的。\n\n\n\n## SpringCloud Gateway\n\n既然选择了Gateway,我们现在就简单介绍下Gateway的用法，以下是Gateway的框架图：\n\n![Gateway框架](/images/video/gateway网关图.png)\n\n可以看出其实Gateway的架构其实是非常简单。Gateway有几个概念：Route、Predicate与Filter\n\n**Route**\n网关配置的基本组成模块，和Zuul的路由配置模块类似。一个Route模块由一个 ID，一个目标 URI，一组断言和一组过滤器定义。如果断言为真，则路由匹配，目标URI会被访问。\n\n\n**Predicate**\n\nPredicate是一个Java8的函数，输入类型是Spring的ServerWebExchange，允许匹配来自Http的任何内容，如请求头或者参数。\n\n![Predicate功能图](/images/video/gateway断言.png)\n\n\n**Filter**\n使用特定工厂构建的Spring GatewayFilter实例，可以在发生下游请求之前修改请求信息或者响应请求之后修改返回内容（这一点与Zuul的过滤器一致）。\n\n![Filter功能图](/images/video/gateway触发器.png)\n\n\n\n## 如何自定义开发Filter\n\n1. 继承AbstractGatewayFilterFactory默认的抽象类,并实现apply的方法\n\n```\n/**\n * @description: 替换服务地址过滤器\n * @author: lhj\n * @Date: 2021年1月16日 下午5:00:00\n */\n@SuppressWarnings({ \"rawtypes\" })\npublic class ProvideServiceGatewayFilterFactory extends AbstractGatewayFilterFactory {\n\tprivate static final Logger LOG = LoggerFactory.getLogger(ProvideServiceGatewayFilterFactory.class);\n\tprivate CrudService<RuleTransformEntity> ruleService;\n\tpublic ProvideServiceGatewayFilterFactory() {\n\t\tsuper();\n\t}\n\tpublic ProvideServiceGatewayFilterFactory(CrudService<RuleTransformEntity> ruleService) {\n\t\tsuper();\n\t\tthis.ruleService = ruleService;\n\t}\n\t@Override\n\tpublic GatewayFilter apply(Object config) {\n\t\treturn (exchange, chain) -> {\n\t\t\tSimpleRespTaskEntity taskEntity = exchange.getAttribute(WebExchangeUtils.RESP_BASE_TASK_ENTITY);\n\t\t\tNetworkNature networkNature = exchange.getAttribute(WebExchangeUtils.NETWORK_TYPE);\n\t\t\tObject startTime = exchange.getAttribute(WebExchangeUtils.START_MILLIS);\n\t\t\tMap<String, String> urls = taskEntity.getUrls();\n\t\t\turls.entrySet().forEach(entry -> {\n\t\t\t\tString schemaUrl = entry.getKey();\n\t\t\t\tString url = entry.getValue();\n\t\t\t\ttry {\n\t\t\t\t\tURI uri = URI.create(url);\n\t\t\t\t\tString path = uri.getPath();\n\t\t\t\t\tString key = url.substring(0, url.indexOf(path)) + \"-\" + networkNature;\n\t\t\t\t\tRuleTransformEntity transform = ruleService.get(key);\n\t\t\t\t\tLOG.info(\"key:{},transform:{}\",key,transform);\n\t\t\t\t\tif (!Objects.isNull(transform)) {\n\t\t\t\t\t\tString transformUrl = url.replace(transform.getSourcePrefix(), transform.getTargetPrefix());\n\t\t\t\t\t\turls.put(schemaUrl, transformUrl);\n\t\t\t\t\t}\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\tLOG.error(e.getMessage());\n\t\t\t\t}\n\t\t\t});\n\t\t\tLOG.info(\"transform urls:{},spends {} ms\", urls,\n\t\t\t\t\tSystem.currentTimeMillis() - Long.parseLong(startTime.toString()));\n\t\t\treturn WebfluxUtil.writeResponse(ResponseResult.fromData(taskEntity), exchange.getResponse());\n\t\t};\n\t}\n}\n```\n\n2. 将这个工厂注入到spring容器当中\n\n```\n@Bean\npublic ProvideServiceGatewayFilterFactory replaceServiceGatewayFilterFactory(CrudService<RuleTransformEntity> ruleTransformManagerService) {\n\treturn new ProvideServiceGatewayFilterFactory(ruleTransformManagerService);\n}\n```\n\n3. 配置yml文件\n\n```\n  cloud:\n    gateway:\n      routes:\n        - id: stream\n          uri: http://{server}/mag-cluster-server/\n          predicates:\n            - Path=/api/video/startTransform/**\n            - name: ReadBodyPredicateFactory \n              args:\n                inClass: \"#{T(String)}\"\n                predicate: \"#{@testRequestBody}\"\n          filters:\n            - ProvideService\n```\n\n## 参考\n1. [Gateway官方文档](https://docs.spring.io/spring-cloud-gateway/docs/current/reference/html/)","tags":["视频"],"categories":["视频"]},{"title":"视频性能压测","url":"/2021/07/22/视频性能压测/","content":"\n## 背景\n由于项目接入了二千多路摄像头，三十台机器集群，应项目的要求对程序项目进行压测，目标是测试到一台流媒体服务器能同时并发支撑多小路视频，从而推测整个集群的能力，也为以后的扩展。\n\n## 前期准备\n\n- 服务器1台\n\n  配置：CPU 8核,内存 16G\n- 客户端1台\n\n  配置：CPU 8核,内存 16G\n- 监控服务端工具nmon：\n- 压测工具：自研发的一款拉流工具，针对我们视频项目接口定制化开发\n\n- 300个海康摄像头1920×1080P(可用正式环境)\n\n## 压测\n\n在压测的时候我认为需要清楚了解整个网络架构图，这样才能发现哪些地方存在的瓶颈，便于后期针对瓶颈地方进行压测。以下是我大致画出当时项目的网络环境：\n\n![网络架构图](/images/video/压测流程图.png)\n\n\n经过分析，存在瓶颈：\n1. 客户端自研拉流程序m1存在拉流的性能瓶颈\n2. 流媒体北向的拉流分发能力m2的瓶颈\n3. 流媒体南向的推流能力m3的瓶颈\n4. 验证m4出口是否有千兆带宽\n\n\n### 场景一\n\n场景：多个用户，同时访问1路摄像头视频\n\n目的：测出单台流媒体服务北向分发能力m2的极限。\n\n为了减少自研发的客户端拉流程序瓶颈对本次压力测试造成影响，使用多个客户端进行拉流。  \n\n![场景一](/images/video/压测结果一.png)\n\n结论：160个用户访问同一路摄像头视频时，系统能够稳定工作；北向并发能力达到160以上。\n\n### 场景二\n\n场景：两个客户端分别请求N路不同的视频，共请求2N路视频。每路视频1人观看。\n\n目的：测出单台流媒体服务南向m3能力的极限。\n\n![场景二](/images/video/压测结果二.png)\n\n\n结论：南向并发处理80路摄像头视频时，系统能够稳定工作；南向并发处理100路摄像头视频时，网络出现较大波动；因此，单个流媒体服务的南向处理能力，为90路视频。\n\n\n### 场景三\n\n场景：两个客户端，分别请求两个不同的流媒体服务器；每个客户端请求N路视频，共请求2N路视频。\n\n目的：南向交换机性能瓶颈测试。\n\n![场景三](/images/video/压测结果三.png)\n\n\n结论：单台客户端服务器最高可以处理南向70路视频，\n单台流媒体服务器最多可处理南向90路视频。\n\n\n### 场景四\n\n场景：两个客户端，分别请求一台服务器上的两个流媒体服务；每个客户端请求N路视频，共请求2N路视频。\n\n目的：压测m4出口带宽是否达到千兆瓶颈\n\n![场景四](/images/video/压测结果四.png)\n\n结论：当请求并发90路视频时，单台流媒体服务器系统能够稳定工作，当并发请求100路视频时，网络IO出现较大波动。因此，单台流媒体服务器南向摄像头最多只能处理90路视频\n\n## 总结\n\n其实对于我来说，有幸参与了这次压测的整个过程，其中包括了跟项目组的沟通，跟第三方供应商技术交流等等。其实对于这类压测，最好能确认好控制单一要素，控制单一要素那就需要将每个步骤分层，然后将其余部分当作整体看待。举个例子，要想测试m3南向并发处理能力，那就将m3往下的部分当作整体，将其他没关要素降到影响最低（譬如客户端是瓶颈因素，那就水平扩展客户端），逐步增大压力，观察服务器等指标，如果出现一些业务报错或者其他问题往往就是触发到瓶颈，这个需要根据业务场景来定。由于我们这里偏向于IO密集型，所以一般都是观察网络IO主要是上下行带宽的指标为主。\n\n\n","tags":["视频"],"categories":["视频"]},{"title":"书籍记录","url":"/2018/01/25/书籍记录/","content":"\n### 1.鸟哥linux第三版基础篇（看完整本书基本上linux入门）\n\n### 2.鸟哥linux第四版基础篇\n\n### 3.Java多线程编程核心技术 (关于线程比较基础入门)\n\n### 4.redis入门指南2 (比较详细记录了redis使用)","tags":["书籍篇"],"categories":["笔记","书籍"]},{"title":"nginx原理分析","url":"/2017/12/05/nginx原理分析/","content":"**导语:**\n>本章主要记录一下我对nginx原理的理解，以及相关的重点与难点\n\n### 一.nginx优点\n\n#### IO多路复用（重点）\n前一章中提及到了nginx能支撑高并发的一个主要原因就是使用到io多路复用的这种技术。\n\n1.  什么是io多路复用？\n定义上：获取并监听多个fd(文件描述符)，通过单个线程内完成IO的读写,复用指的是线程\n例子:某快递公司快递员（<font color=\"red\">处理线程</font>），寄件（<font color=\"red\">IO网络请求</font>）\n    * 例子一：快递员不知道哪家需要寄件，逐间逐户询问是否需要寄件，这样的话就会造成耗费时间过长，万一某一户出现某些情况，寄件人还未回来，就会一直阻塞。这就是一个典型的单线程阻塞例子。\n    * 例子二：快递公司觉得一个快递员收件太慢了，就聘请了多个快递员去收件。这样会造成一个问题就是收件速度确实比以前快，但这也会使快递公司成本变得高，造成不必要的人力浪费。这个就是多线程+阻塞的例子。\n    * 例子三：寄件方准本好需要的寄件，然后打电话通知快递员某户寄件已准备好，快递员就上门收取。这样就能用一个快递员高效的收纳寄件。这就是一个io多路复用的例子，打电话通知寄件已准备好其实可以看作io事件准备就绪主动上报的一个过程，程序机制就会对已准备好的事件做一系列的io读写操作。\n\n1. nginx的io多路复用模型有哪些？\nnginx中提供了多种io多路复用模型的机制如select,poll,epoll等。目前，linux2.6以上才能使用epoll机制。本质上,select与epoll都是属于非阻塞的同步IO.下面，我简单介绍一下select与epoll的区别。\n    - select介绍\n    ![selectIO模型图](/images/nginx/select.jpg)\n    1. 进程通过select调用，将fd集合从用户态全部复制到内核态当中，这个过程中会阻塞进程。\n    2. select会遍历的fd集合，如果存在准备就绪的fd，就会返回可读的指示并将对应连接放入监听队列中(表示监听IO数据)。在第二次遍历如果发现存在已经就绪的数据，则会调用recvfrom的方法,进程会将数据从内核态复制到用户态中并进行对应读写事件处理。处理完毕则会移除对应监听队列的socket。\n    3. 在select遍历完所有的fd都没有发现可读的fd后,则会进入休眠期。当有发现新的可读写资源，则会唤醒select进程。如果超过一定超时时间，则会重新被唤醒。重新遍历fd集合。\n        <span><font color=\"red\">\n        select总结:\n            -  每次select调用都需要遍历fd集合。\n            -  监视的文件描述符的数量存在最大限制，可以调节，但是随着增大也会导致用户态与内核态之间的复制带来的资源开销（如内存）呈线性增大\n            -  每次都要将整个集合的数据在用户态与内核到之间的互相复制。\n        </font></span>\n        \n    - epoll介绍\n    epoll的核心主要是三个函数:epoll_create(创建epoll句柄)，epoll_ctl(管理epoll注册监听事件，增删查改等)，epoll_wait(等待执行事件)\n    4. 首先调用epoll_create创建一个epoll句柄对象，epoll含有一个红黑树和一个就绪队列。\n    5. 当调用epoll_ctl创建注册监听事件时候，会为fd注册一个回调函数，并将fd从用户态复制到内核态。如果fd就绪后，会通过回掉函数将fd放入就绪队列中。\n    6. epoll_wait则会扫描就绪队列并执行相应事件,并把数据返回给用户。与select类似都是苏醒与睡眠交替进行，但是select是不停遍历整个fd集合，而epoll_wait只是遍历就绪列表就可以了，仅判断是否为空就OK拉。\n> 总结：  \n简单类比一下，其实select模型与epoll模型好比如在茶楼结账时候，服务员只告诉老板有人结账了，你过去收。此时老板并不知道具体要结账的是哪一桌，就一个一个去问（遍历fd集合是否有就绪），这是select模型做的；而epoll则是服务员具体告诉老板是那几桌要结账（利用回调函数，将就绪事件直接放到epoll队列中），老板就能直接过去结账。\n\n1. io多路复用的优缺点?\n\n| 优点 | 缺点 |\n| :---: | :---: |\n|单线程，消耗少|不适宜处理少量的请求数|\n|能支撑大并发量的请求|\n|非阻塞|\n\n#### cpu的亲和性\n能够将nginx上的worker绑定到某一特定的cpu上，这样大大避免了进程中缓存的丢失以及切换带来的资源消耗。而且，nginx中还会将某些字符串转换成特定的int，再进行比较，减少了指令条数（如nginx在解释请求头中的method信息时候,会将其值（post|get）转换成int类型进行比较）\n\n#### 轻量级\nnginx只保留核心功能模块，而且并不多，可进行相应扩展。\nnginx模块化开发，比较易读\n\n### 二.nginx 工作原理\n![nginx工作图解](/images/nginx/worker.jpg)\n- master进程工作范围\n    -  master负责接收外界的信号并分发给worker各个进程。worker进程会通过抢排斥锁accept_mutex来抢占资源（各个worker抢占资源是有一个算法，能均衡每个worker抢占到的资源）\n    -  master管理和监控着各个worker的运行状态。\n    -  master加载配置文件(如执行重启，关闭操作)。如重启操作，首先重新加载配置文件，fork出新的worker并通知旧的worker停止接收资源，等到旧worker已经完成了剩下的请求后就退出。\n- worker进程工作范围\n    -  每个抢到互斥锁的worker进程会进行读取请求、解释请求、处理请求、产生数据、返回客户端的步骤。\n\n### 三.nginx中对connection流程\n<center>\n\n```flow\nst=>start: 开始\nstep1=>operation: 客户端与nginx通过三次握手tcp连接,并创建好socket\nstep2=>operation: worker抢占锁并将connection封装到ngx_connection_t实体中\nstep3=>operation: 将socket设置好读写事件\nstep4=>operation: 与其他server创建连接与创建\nngx_connection_t实体并设置好读写事件\n\nstep5=>operation: 执行读写事件，完成后nginx与客户端交换数据\nstep6=>operation: 释放ngx_connection_t,nginx或客户端主动关掉连接\ncond=>condition: 是否有其他server(如upstream等)\ne=>end: 结束\nst->step1\nstep1->step2\nstep2->step3->cond\ncond(yes)->step4\ncond(no)->step5\nstep4->step5->step6->e\n```\n</center>\n\n### 四.总结\n以上是经过我这一段时间对nginx的了解作出的总结，可能会有一些偏差或者不够完善的地方。在今后会不停地去反复完善，希望能将nginx理解得更为透彻。\n\n### 五.参考\n1.  [io模式与IO](https://www.cnblogs.com/zingp/p/6863170.html)\n2.  [select模型的说明](https://www.jianshu.com/p/edb9ddd51c3d)\n3.  [nginx从入门到精通](http://tengine.taobao.org/book/)\n\n","tags":["总结"],"categories":["nginx总结"]},{"title":"nginx的搭建","url":"/2017/11/30/nginx搭建与部署/","content":"\n### nginx是什么\nnginx是一个开源且高性能、可靠的http中间件、代理服务\n\n### 为什么使用nginx（详细在下一章总结）\n- io多路复用(select,epoll等模型实现)\n- cpu亲和性\n- 轻量级\n\n### nginx的使用场景 （详细在另外一章总结）\n1. 代理服务\n    1. 正向代理\n    2. 反向代理\n2. 缓存服务\n3. https服务\n4. 静态web服务\n    1. 跨域\n    2. 防盗链\n    3. 客户端缓存\n5. 动静分离\n6. nginx+lua \n    1. 流量监控\n    2. waf\n    3. 灰度发布(建议使用openresty)\n7. rewrite规则\n    1. 后台维护页面\n    2. seo搜索优化\n    3. 安全（伪静态）\n    4. url访问跳转（新旧域名替换）\n\n### nginx下linux的部署(fedora27)\n    简单说明下安装nginx的所需要的依赖，并不做详细讲解\n1. 下载prec,zlib,openssl\n2. yum install -y gcc g++ (c编译工具)\n3. yum install -y pcre pcre-devel(重写rewrite,正则表达式)\n4. yum install -y zlib zlib-devel(gzip压缩)\n5. yum install -y openssl openssl-devel\n6. 下载nginx（可到官网上下载.tar文件）\n7. 解压 tar -zxvf nginx-xxxx.tar.gz\n8. 进入解压目录，并执行./configure --prefix=/usr/local/nginx  \n9. make && make install\n\n### nginx的目录配置说明\n├── auto            自动检测系统环境以及编译相关的脚本\n│   ├── cc          关于编译器相关的编译选项的检测脚本\n│   ├── lib         nginx编译所需要的一些库的检测脚本\n│   ├── os          与平台相关的一些系统参数与系统调用相关的检测\n│   └── types       与数据类型相关的一些辅助脚本\n├── conf            存放默认配置文件，在make install后，会拷贝到安装目录中去\n├── contrib         存放一些实用工具，如geo配置生成工具（geo2nginx.pl）\n├── html            存放默认的网页文件，在make install后，会拷贝到安装目录中去\n├── man             nginx的man手册\n└── src             存放nginx的源代码\n    ├── core        nginx的核心源代码，包括常用数据结构的定义，以及nginx初始化运行的核心代码如main函数\n    ├── event       对系统事件处理机制的封装，以及定时器的实现相关代码\n    │   └── modules 不同事件处理方式的模块化，如select、poll、epoll、kqueue\n    ├── http        nginx作为http服务器相关的代码\n    │   └── modules 包含http的各种功能模块\n    ├── mail        nginx作为邮件代理服务器相关的代码\n    ├── misc        一些辅助代码，测试c++头的兼容性，以及对google_perftools的支持\n    └── os          主要是对各种不同体系统结构所提供的系统函数的封装，对外提供统一的系统调用接口\n\n\n\n### nginx相关命令\n```nginx\n./nginx 启动\n./nginx -s stop 关闭\n./nginx -s reload 重启\n./nginx -tc nginx 配置文件   检测nginx配置文件语法\n```\n\n### **<font color=\"red\"> 注意 </font>**\n- 在重新编译nginx时候，先将原有的nginx二进制文件备份,再执行./configure && make && make install 以免被新的nginx覆盖\n- 若直接使用yum最新版本的openssl,则会在编译某些旧版本nginx的时候出现不兼容的情况。原因是由于openssl新版本改动得挺大导致。解决方案\n    - 升级nginx版本\n    - 降级openssl的版本(额外章会记录如何降级，这里遇到了一个坑) \n\n### 参考文献\n1. [nginx从入门到精通](http://tengine.taobao.org/book/)\n2. [nginx中文官方文档](http://www.nginx.cn/doc/)\n","tags":["总结"],"categories":["nginx总结"]},{"title":"kettle-8.2安装手册","url":"/2017/08/21/kettle-8.2安装手册/","content":"\n# 1 简介\n本编文章主要介绍如何安装kettle 8.2\n\n# 2 准备\n  1) 安装jdk1.8(已在上一章说明)\n  2) 下载kettle 8.2安装包：*[https://sourceforge.net/projects/pentaho/files/latest/download?aliId=137249511](https://sourceforge.net/projects/pentaho/files/latest/download?aliId=137249511)*\n# 3 安装kettle 8.2\n  1) 解压下载的安装包\n  2) 进入目录pdi-ce-8.2.0.0-342 **->** data-integration **->** ,打开spoon.bat\n![spoon-bat](/images/bdata/kettl-pc启动器.png)\n  3) 出现以上页面，代表安装成功\n![success-page](/images/bdata/kettle-pc界面.png)\n\n# 4 如何运行kettle脚本程序\n  1) 下载kettle脚本程序.zip,并重命名成后缀为zip压缩包：*[http://192.168.2.45:1174/AAYQAf__AAAAAQAAAAAAAAAAyUKMcgAORL6xOFABvf-aoA](http://192.168.2.45:1174/AAYQAf__AAAAAQAAAAAAAAAAyUKMcgAORL6xOFABvf-aoA)*\n  2) 解压压缩包，获取rest2file.ktr脚本程序\n  3) 点击打开按钮并选择存放脚本的指定位置\n![open](/images/bdata/kettle打开界面.png)\n  4) 执行脚本，并看当前脚本返回结果\n![perform](/images/bdata/kettle执行按钮.png)","tags":["大数据"],"categories":["大数据"]},{"title":"git指令用法","url":"/2017/02/23/git常用指令记录/","content":"\n### 常用git命令的使用\n```github\ngit init 初始化当前文件夹\n#分支\ngit branch -r 查看已有的分支\ngit checkout -b 分支 创建并切换分支\ngit checkout 分支 切换分支\ngit branch 显示当前分支\ngit branch -d 分支 删除分支\n#提交\ngit add . 添加操作，将将所有修改过的文件添加到版本库的暂缓区内\ngit commit -m \"文字说明\" 提交操作，将暂缓区内的代码提交到本地仓库中\ngit push origin 分支 push到远程仓库中\n#版本回退\ngit reset HEAD^ 回退到上一个版本\ngit reset --hard commit_id 回退到指定的commit_id的版本中\n#添加远程仓库\ngit remote add origin git@github.com:245831311(github账号名)/245831311.github.io.git(github仓库名)  添加远程仓库\ngit remote -v 查看origin远程主机名对应远程仓库\ngit remote rm origin 删除远程仓库\n#查看配置\ngit config -l 查看\n#查看git状态\ngit status\n#拉取代码\ngit fetch 将远程分支上的代码拉取下来并不合并\ngit rebase\ngit merge 合并代码\ngit pull 拉取并与当前分支合并代码\n```\n\n### 重点记录\n#### 1.git push <远程主机名> <本地分支名>  <远程分支名>\n__1.1 git push origin__\n 省略了本地分支与远程分支，当前分支与上一次的远程分支存在对应的关系，则会通过这个关系推送出去\n__1.2 git push origin master__\n 省略了远程分支名，则本地分支会推送到上一次对应存在的远程分支关系(一般同名).不存在则创建新的远程分支\n__1.3 git push origin :refs/for/master__\n 省略了本地分支名，则相当与删除远程分支\n__1.4 git push -u origin master__\n-u可以将本地分支与远程分支建立一个upstream的关系，若使用，则本地分支与远程分支建立了对应关系\n\n\n\n\n\n","tags":["笔记"],"categories":["git总结"]},{"title":"hexo的搭建与使用","url":"/2017/02/22/hexo用法/","content":"\n### Hexo 是什么\n    hexo是基于node.js的一个简洁的博客框架。hexo是一款使用markdown渲染，快速生成静态页面的框架。\n\n### 为什么使用hexo作为博客\n* 不走数据库，可以通过md作为存储文件\n* 高效快速，生成和渲染静态页面快\n* 部署发布简单，操作简便\n\n### hexo部署\n一. 安装node.js（网上很多，不详细解释）\n安装完毕后可以输入node -v查看是否安装成功.\n\n二. 安装hexo\n```html\n#由于npm的源比较慢，建议先换成淘宝的镜像\nnpm config set registry \"https://registry.npm.taobao.org\"\n\n#安装hexo客户端\nnpm install hexo-cli g\n\n#安装服务端插件\nnpm install hexo-server --save\n\n#安装hexo发布插件\nnpm install hexo-deployer-git --save\n```\n### hexo相关语法\n```hexo\n1.hexo init 文件夹 初始化文件夹为hexo目录形式\n2.hexo server(hexo s) 开启服务端,默认4000\n3.hexo s -p 5000 开启服务端并设置端口号\n4.hexo generate(hexo g) 生成静态页面\n5.hexo clean 清空静态页面\n6.hexo deploy 发布\n7.hexo g -d 生成并发布\n8.hexo g -s 生成并开启服务\n```\n\n","tags":["笔记"],"categories":["hexo总结"]},{"title":"st3使用配置","url":"/2017/01/22/使用Sublime3/","content":"\n---\n该编文章主要是记录下使用ST3和在ST3编辑markdown\n---\n\n### 1. 安装ST3\n安装过程及其简单，直接go to anything 就可以了。\n\n### 2. 下载支持插件\n1. 下载package control插件(网上一堆信息，不做详细说明)\n主要参考：[https://www.cnblogs.com/luoshupeng/archive/2013/09/09/3310777.html/](https://www.cnblogs.com/luoshupeng/archive/2013/09/09/3310777.html/)\n2. 下载markdownEditing(编辑markdown,提供快捷键)\n*流程:ctrl+Shift+P->install package->下载markdownEditing插件->在multimarkdown setting user下设置*\n```\n{\n      \"enable_table_editor\": true,\n      \"highlight_line\": true,\n      \"line_numbers\": true,   // 显示行号\n      \"tab_size\": 4,          // tab宽度\n      \"wrap_width\": 300,\n      \"word_wrap\": true,      // 自动换行\n      \"color_scheme\": \"Packages/MarkdownEditing/MarkdownEditor-Dark.tmTheme\",\n      // \"color_scheme\": \"Packages/MarkdownEditing/MarkdownEditor.tmTheme\",\n      // \"color_scheme\": \"Packages/MarkdownEditing/MarkdownEditor-Dark.tmTheme\",\n      // \"color_scheme\": \"Packages/MarkdownEditing/MarkdownEditor-Yellow.tmTheme\",\n      \"mde.keep_centered\": true,// 可以保持你正在编辑的行始终处于屏幕的中间\n      \"extensions\":\n      [\n          \"mmd\",\n          \"md\"\n      ]\n }\n```\n3. 下载Markdown Preview或MarkdownLivePreview.(预览markdown)\n_markdown preview下载流程:ctrl+Shift+P->install package->输入插件名称markdown preview->key bindings插入下面代码_\n```\n{ \"keys\": [\"alt+m\"], \"command\": \"markdown_preview\", \"args\": {\"target\": \"browser\", \"parser\":\"markdown\"} },   \n```\n\n\n### 3. 记录st3常用的快捷键\n```java\nCtrl+← 向左单位性地移动光标，快速移动光标。\nCtrl+→ 向右单位性地移动光标，快速移动光标。\nshift+↑ 向上选中行。\nshift+↓ 向下选中行。\nCtrl+Shift+K 删除整行。\nCtrl+/ 注释单行。\nCtrl+Shift+/ 注释多行。\nCtrl+K+U 转换大写。\nCtrl+K+L 转换小写。\nCtrl+F 打开底部搜索框，查找关键字。\nCtrl+P 打开搜索框。提供：1、输入当前项目中的文件名，快速搜索文件，2、Ctrl+G功能，3、Ctrl+R功能，4、Ctrl+：功能\nCtrl+G 自动带：，输入数字跳转到该行代码\nCtrl+R 自动带@，查找文件中的函数名\nCtrl+： 自动带#，查找文件中的变量名、属性名等\nCtrl+Shift+P 打开命令框。场景栗子：打开命名框，输入关键字，调用sublime text或插件的功能，例如使用package安装插件。\nEsc 退出搜索框，命令框等。\nAlt+Shift+1 窗口分屏1-4(水平),5（等分）,89（垂直）\nCtrl+K+B 开启/关闭侧边栏。\n```\n\n### 4. markdownEditing常用的快捷键\n```java\nCtrl+Win+V 选中的内容将自动转换为行内式超链接，链接到剪贴板中的内容\nCtrl+Win+R 选中的内容将自动转换为参考式超链接，链接到剪贴板中的内容\nCtrl+Alt+R 弹出提示框插入一个参考式超链接，在提示框中输入链接内容和定义参考ID[^3]\nCtrl+Win+K 插入一个标准的行内式超链接\nWin+Shift+K 插入一个标准的行内式图片（此快捷键可能与输入法有冲突）\nCtrl+1 至 Ctrl+6 插入一级至六级标题\nFN+Alt+i 选中的内容转换为斜体\nFN+Alt+b 选中的内容转换为粗体[^1]\nCtrl+Shift+6 自动插入一个脚注，并跳转到该脚注的定义中。\nAlt+Shift+F 查找没有定义的脚注并自动添加其定义链接\nAlt+Shift+G 查找没有定义的参考式超链接并自动添加其定义链接\nCtrl+Alt+S 脚注排序\nCtrl+Shift+. 缩进当前内容\nCtrl+Shift+, 提前当前内容\n```\n\n__PS__ 参考:\n1. 快捷键总结:[http://blog.csdn.net/u012771929/article/details/30030249](http://blog.csdn.net/u012771929/article/details/30030249)\n2. st3使用配置:[http://www.jianshu.com/p/62241c7ecec9](http://www.jianshu.com/p/62241c7ecec9)","tags":["笔记"],"categories":["sublime3使用笔记"]}]